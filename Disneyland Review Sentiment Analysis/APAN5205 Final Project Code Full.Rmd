---
title: "APAN5205: Text Analysis for Disneyland Park Online Reviews"
author: "Group 6: Yancheng Yu, Jiale Gao, Ruolin Li, Rui Wang, Qinyao Jiang,ZiYan Cui"
date: "2023-03-19"
output: 
  html_document:
    toc: true
    toc_float: true
---
## Introduction

  Disneyland is a world-renowned destination for visitors of all ages seeking an immersive entertainment experience. With multiple locations across the globe, Disneyland attracts people from all over the world, and provides visitors with unique cultural and recreational experiences. Understanding and catering to visitor’s demands and expectations is one of the most crucial aspects of running a successful Disneyland Branch.   
  
  This analysis aims to explore and identify the key factors that visitors care about during their visits to Disneyland at different locations across the world. Extensive research on visitors’ reviews and ratings will be conducted using a dataset that includes 42000 reviews and ratings of 3 most famous Disneyland branches - Paris, California, and Hong Kong. Another dataset used to support the analysis contains locations and types of Disneyland’s rides, which covers the majority of the rides facilitated at the three branches in this study. Other data such as general information about each branch will be collected and analyzed to support the study of visitor expectations.   
  
  Research questions exploring features that are potentially relevant to the sentiment of the review and/or the rating value would be raised and studied. These features include Park area, waiting times for rides, rides experience, amount of visitors, firework experiences, etc. By answering these questions, this analysis reveals insights about visitors’ perspectives and behaviors and will accordingly provide recommendations on how Disneyland at different locations may improve their offerings, enhance visitor experiences, and increase the overall satisfaction of visitors. With the recommendations, this research is expected to aid Disneyland to optimize its operations and make informed decisions for the future.


## Literature Review

  By extracting data from an online review platform and pre-processing using text processing techniques, Jian Ming Luo and his team indicates that the popularity of topic words varies amongst theme parks and groups of visitors from different countries with topic modeling techniques (Luo & Yu, 2020). In their research, a comprehensive list of topics discussed by visitors in their reviews when visiting Disneyland theme parks is constructed to explore its relationship with review rating, which include “value for money”, “Dining options” and “Booking system” etc. It reveals that visitors tend to provide high ratings when they share happy experiences, while they tend to provide low ratings when they share other experiences such as value for money, food price, and cleanliness (Luo & Yu, 2020). Luo (2020) also mentions that queue time for riding is an important factor that negatively affects visitors’ experience, which results in low ratings. This review discusses the relationship between topic words existing in reviews and ratings by constructing topic modeling, which provides future research directions. It also illustrates the computation and frequency of topic probability by theme parks and visitors groups, which inspires our research to categorize reviews based on visitors’ nationality and locations of Disneyland they visited.


## Research Plan

### Explain variables/describe the data
The dataset we used for our analysis is called “Disneyland Reviews” (Kaggle, 2021). It contains information about the reviewer, the review text, and the location of the Disneyland they reviewed for. It contains 6 columns and 42,657 rows, the columns are:    
1. 	`Review_ID`: the unique id given to each review, there are 42,632 reviews in total;  
2. 	`Rating`: the rating that the visitor gave to the theme park, ranging from 1 (unsatisfied) to 5 (satisfied);  
3. 	`Year_Month`: the month and year when the reviewer visited the theme park, it’s in YYYY-MM format;  
4. 	`Reviewer_Location`: the country of origin of the reviewer, 34% of them are from United States and 23% of them are from United Kingdom;  
5. 	`Review_Text`: the comments made by the reviewer;  
6. 	`Disneyland_Branch`: the location of the Disneyland Park the reviewer visited, it includes 3 locations - California, Hong Kong, and Paris.  
The independent variables include review_text and year_month, and the dependent variable is rating.  

Another dataset we used for further exploration of the rides’ feature is called “WDW_Ride_Data_DW” (data.world, 2018). This dataset explains the locations and types of Disneyland’s rides. Even though this dataset mainly describes rides in Disney World in Orlando, it covers some rides in the three Disneylands we are analyzing, especially the Magic Kingdom Theme Park. Adding this data may help enhance the understanding of rides’ attributes, such as darkness, intensity, speed and targeting demographics, thus detailing the rides as a factor to predict rating in a regression model.  
After cleaning, this dataset contains 22 columns and 47 rows, the columns are:  
1. `Ride_name`: the full name of the ride;  
2. `Park_location`: the park name where the ride is located. (magic kingdom, animal kingdom, epcot, Hollywood studios);  
3. `Park_area`: the specific area inside the park where the ride is located;  
4. `Ride_type_all`: the specifications of ride styles, the following 8 columns contain Boolean values indicating whether the type of the ride is thrill/spinning/slow/small drops/big drops/dark/scary/water;  
5. `Fast_pass`: whether the ride offers fast pass;  
6. `Classic`: whether the ride is considered as a classic ride;  
7. `Age_interest_all`: the specifications of age ranges that would enjoy this ride, the following 5 columns contain Boolean values indicating whether the age area of preschoolers/kids/tweens/teens/adults would enjoy this ride;  
8. `Height_req_inches`: the height requirements of riders in inches;  
9. `Ride_duration_min`: how long the ride lasts (nearest quarter minute).


### Research Questions

To examine the characteristics of online reviews that could potentially influence ratings of Disneyland Parks, and look for potential improvements for better visitor experience, we formulated the following potential research questions:    
  
1. What is the relationship between reviewer location and the popularity of topics in their reviews?   
Hypothesis 1:   
Ho: Reviewers from different countries focusing on describing the same Disney experience topics.  
Ha: Reviewers from different countries focusing on describing different Disney experience topics.  
Hypothesis 2:  
Ho: Reviewers from America and Canada mention car adventures in their reviews at the same or less frequency as reviewers from other countries.  
Ha: Reviewers from America and Canada mention car adventure in their reviews more frequently than others.  
Hypothesis 3:  
Ho: Reviewers from Asian countries mention food in the reviews at the same or less frequency as reviewers from other continents. 
Ha: Reviewers from Asian countries mention food in their reviews more frequently than reviewers from other continents. 
  
2. What is the relationship between Disneyland branches’ locations and the popularity of topics in reviews?   
Hypothesis 1:   
Ho: Reviews from different Disney branches focus on the same topics.  
Ha: Reviews from different Disney branches focus on different topics.  
Hypothesis 2:  
Ho: Hong Kong Disneyland receives reviews related to shopping experiences in similar proportion as other branches.  
Ha: Hong Kong Disneyland receives reviews related to shopping experiences in different proportion as other branches.  
Hypothesis 3:  
Ho: California Disneyland receives reviews related to rides experiences in similar proportion as other branches.  
Ha: California Disneyland receives reviews related to rides experiences in different proportion as other branches.     
  
3. We classified the topic words in the reviews into four categories: time, theme rides, dining, and customer services. Which specific topic words & topic words categories do reviewers share in their reviews when they tend to provide a high & low ratings?   
Hypothesis 1:  
Ho: Reviews discussing time words would not affect overall review ratings.  
Ha: Reviews discussing time words would affect overall review ratings.  
Hypothesis 2:  
Ho: Reviews discussing food words would not affect overall review ratings.  
Ha: Reviews discussing food words would affect overall review ratings.  
Hypothesis 3:  
Ho: Rides features would not affect overall review ratings.  
Ha: Rides features would affect overall review ratings. 
Hypothesis 4:  
Ho: Reviews discussing staff would not affect overall review ratings.  
Ha: Reviews discussing staff would affect overall review ratings.  



## Data Cleaning

In this part, for the Disneyland dataset, we dropped missing values, separated Year and Month as independent columns, added a column to classify ratings into 3 categories: rating 1 and 2 as negative, 3 as neutral, and 4 and 5 as positive. We also added a continent column to our dataset to categorize reviewer’s resident locations. In the Rides dataset, we removed the missing value, converted “yes” and “no” in rides’ features columns into 1 and 0, and dropped redundant columns.  

#### Disneyland Data

```{r, message=FALSE}
library(stringr)
library(dplyr)
disney<-read.csv("DisneylandReviews.csv")
#summary(disney)
str(disney)
glimpse(disney)
```

```{r}
which(is.na(disney))
head(unique(disney$Year_Month))

missing<- disney %>% 
  filter(Year_Month == "missing")
#head(missing)
dim(missing)
```
There is no NA's in the disney dataset. But by observing unique values under the `Year_Month` column, we found that the dataset contains 2613 missing values in the column `Year_Month`. The unclear years and months of these comments will affect our analysis and understanding of the three Disneyland, so we dropped the missing values as shown below.

```{r}
disneyland <- subset(disney, Year_Month!="missing")
dim(disneyland)
```

Now the dataset consists of 6 columns and 40043 rows. 

We noticed that the `Year_Month` column is currently character class. We hope to convert it to a date class that could help future analysis. 

```{r, message = F}
#install.packages("zoo")
library(zoo)
disneyland <- transform(disneyland, Year_Month = as.yearmon(Year_Month))
  
```

We want to separate out Year and Month as independent columns so that when exploring the data, the processing steps can be easier. 

```{r, message = F}
#install.packages("lubridate")   
library(lubridate)

disneyland <- disneyland %>%
  mutate(Year = year(Year_Month)) %>%
  mutate(Month = month(Year_Month))

#summary(disneyland)
#head(disneyland)
```

```{r}
# Ratings of Reviews
library(dplyr); library(magrittr)
unique(disneyland$Rating)
disneyland%>%
  summarize(average_rating = mean(Rating), median_rating = median(Rating))

disneyland <- disneyland %>%
  mutate(Rating_type = case_when(Rating >= 4 ~ 'positive',
                                 Rating == 3 ~ 'neutral',
                                 Rating <= 2 ~ 'negative'))
#head(disneyland)
```
We found the ratings of all reviews ranged between 1 to 5 and the ratings are all integers. We calculated the average rating of all 40043 ratings is 4.231102. Based on the calculated average rating, we would add a column that classifies the `rating_type`. Any rating greater than or equal to 4 would be considered as "positive"; any rating that equals to 3 would be considered as "neutral"; any rating less than 3 would be considered "negative."


```{r, message = FALSE, out.width='40%', out.height = '30%'}
# Distribution of Reviews
library(ggplot2)
#install.packages("ggthemes")
library(ggthemes)
ggplot(data=disneyland,aes(x=Rating))+
  geom_histogram(fill='sienna3')+
  theme_bw()+
  scale_x_reverse()+
  xlab('Review Rating')+
  coord_flip()

# count the number of occurrence of each rating
table(disneyland$Rating)
# calculate each rating's proportion among all 40043 reviews
prop.table(table(disneyland$Rating)) 
# count the number of occurrence of each rating_type
table(disneyland$Rating_type)
```
Generally, over half of the total ratings are 5. And the "positive" rating occupies over 75% of the total reviews. Hence, for our future analysis, we would put more focus on evaluating the relationship between features mentioned in positive reviews and the rating.


```{r, message = F, out.width='60%', out.height = '30%'}
#install.packages("DataExplorer")
library(DataExplorer)
#Bar charts and histograms for discrete and continuous variables
plot_bar(disneyland)
plot_histogram(disneyland)
```

From the above bar plots, we again noticed that most of the reviews are positive. And we also noticed that most of the reviews are for Disneyland California branch. So, in our later analysis, we would also focus on if there is a relationship between Disney branch and rating. As well as if there are some features in California branch that are related to the rating type. 

```{r, eval = FALSE}
# Reviewer_Location
length(unique(disneyland$Reviewer_Location))

# Clean locations with special characters
disneyland$Reviewer_Location[disneyland$Reviewer_Location == '\xc5land Islands'] <- 'Five Islands'
disneyland$Reviewer_Location[disneyland$Reviewer_Location == "C\xf4te d'Ivoire"] <- 'Ivory Coast'
disneyland$Reviewer_Location[disneyland$Reviewer_Location == "Cura\xe7ao"] <- 'Curacao'

table(disneyland$Reviewer_Location)
```

There are 162 different `Reviewer_Location` in our dataset. In our future analysis, we would focus on locations/countries that has a relative large amount of reviews. We expected to find if people from different locations would have their preferences features when rating Disney Parks. 

```{r, message = F}
#install.packages("countrycode")
library(countrycode)
disneyland$continent <- countrycode(sourcevar = disneyland[, "Reviewer_Location"],
                            origin = "country.name",
                            destination = "continent")
#head(disneyland)
```
We introduce the `library(countrycode)` to add a continent column to our dataset. In our future analysis, we hope to analyze reviewers' preferences based on their continents and cultures.   


```{r}
#write.csv(disneyland, "/Users/ruolinli/Desktop/APAN 5205/disneyland.csv", row.names=FALSE)
```


#### Rides Data

```{r}
# Load second dataset "rides"
rides <- read.csv("WDW_Ride_Data_DW.csv")
#head(rides)
str(rides)
#glimpse(rides)
```



```{r}
sum(is.na(rides))
rides<-na.omit(rides)
rides<-rides[,-c(23:28)]
#head(rides)
```

There are only four missing values in total so we removed them. As mentioned before, this dataset described the rides information in Orlando, so variables including open days and age of rides could be dropped, which remains a 22-variables dataset.


```{r}
# Convert Yes/No to 1/0
rides <- rides %>%
  mutate(across(c(Ride_type_thrill, Ride_type_spinning, Ride_type_slow,
                  Ride_type_small_drops, Ride_type_big_drops, Ride_type_dark,
                  Ride_type_scary, Ride_type_water, Fast_pass, Classic,
                  Age_interest_preschoolers, Age_interest_kids,
                  Age_interest_tweens, Age_interest_teens,Age_interest_adults), 
                  ~as.numeric(ifelse(.x == "Yes",1,0))))
```

We convert Yes/No values under each column to 1/0 for future analysis. 

```{r, message = F}
#install.packages("ggcorrplot")
library(ggcorrplot)

rides_cor <- rides[,-c(1:4,15)]
ggcorrplot(cor(rides_cor),
           method = 'square',
           type = 'lower',
           show.diag = F,
           colors = c('#e9a3c9', '#f7f7f7', '#a1d76a'))

```

From the correlation plot, we can see that high correlations exist among `Age_interest_tweens`, `Age_interest_teens`, and `Age_interest_adults`, also between `Height_req_inches` and `Age_interest_preschoolers`, so we may less consider these variables when we analyze rides' attributes. 


```{r, eval = F}
#example code
disney %>%
  filter(str_detect(Review_Text, "big thunder"))
```

In future analysis, we would join the two datasets (and possible other related datasets) together based on rides name mentioned in reviews. We expected to analyze if rides' attributes such as darkness, intensity, speed, and targeting demographics would influence the overall rating customers have on Disney branches. 

```{r}
#write.csv(disneyland, "/Users/ruolinli/Desktop/APAN 5205/rides.csv", row.names=FALSE)
```

## Review Column Explore 

Firstly, we want to get a sense of the `Review_Text` column. Specifically, we want to know the number of characters, words, and sentences across all reviews; percentage of Screaming Review and the percentage of exclamation marks in the review.    
Since using uppercase and exclamation marks is usually a way to express feelings, we want to know if the use of uppercase and exclamation marks in review has any impact on review's overall rating. Whether use of uppercase letters and exclamation marks would associate with more extreme ratings?   
```{r}
#install.packages("readr")
library(readr)
library(tm)
library(dplyr)
library(magrittr)
library(stringr)

#summary of characters, words, and sentences across all reviews
summary(nchar(disneyland$Review_Text))
summary(str_count(string = disneyland$Review_Text, pattern = '\\S+'))
summary(str_count(string = disneyland$Review_Text, pattern =     "[A-Za-z,;'\"\\s]+[^.!?]*[.?!]"))
#get the mean number of characters, words and sentences together
disneyland %>%
  select(Review_Text)%>%
  mutate(characters = nchar(Review_Text),
         words = str_count(Review_Text,pattern='\\S+'),
         sentences = str_count(Review_Text,pattern="[A-Za-z,;'\"\\s]+[^.!?]*[.?!]"))%>%
  summarize_at(c('characters','words','sentences'),.funs = mean,na.rm=T)

#Screaming Reviews:
percentUpper = 100*str_count(disneyland$Review_Text,pattern='[A-Z]')/nchar(disneyland$Review_Text)
summary(percentUpper)

#Exclamation marks:
percentExclamation = 100*str_count(disneyland$Review_Text,pattern='!')/nchar(disneyland$Review_Text)
summary(percentExclamation)

#impact of Upper Case and Exclamation marks on rating
r_upper = cor.test(percentUpper, disneyland$Rating)
r_exclamation = cor.test(percentExclamation, disneyland$Rating)
correlations = data.frame(r = c(r_upper$estimate, r_exclamation$estimate), p_value=c(r_upper$p.value, r_exclamation$p.value))
rownames(correlations) = c('Upper Case','Exclamation Marks')
correlations
```
Given two very small p-value, we could reject the null hypothesis (there is no effect between use of uppercase and exclamation marks and the overall review rating). Hence, we could conclude that the use of uppercase and exclamation marks has certain association with the Disneyland rating given by visitors.  
The use of uppercase might be a way to expression anger. And a set of consecutive exclamation marks may convey surprise or emphasis.  


Now, we want to see what are the words existed frequently in `Review_Text`:  
```{r}
#Finding common words existing in Review_Text (excluding stop words):
library(dplyr)
library(tidytext)
library(magrittr)

#observe and plot the top 25 common words:
disneyland %>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(25)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()
```
From the plot, we can see that words related to disneyland itself appear frequently: "park", "disney", "disneyland", "visit". "rides", "time", "day", "food" and other words also existed frequently. We would explore the relationship between word occurrence and rating in our later research questions.  

For all Disneyland reviews, we wonder if there is more positive feelings or more negative feelings. And what is the relationship between word sentiment and rating? 
```{r}
head(disneyland)
#Use Binary Sentiment Lexicons to classify tokens into two categories: positive and negative
disneyland %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Review_Text)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment) %>%
  count() %>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip() +
  labs(title = "Sentiment Analysis of All Reviews") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))

# Sentiment Analysis of Reviews in Different Rating Categories
library(ggthemes)
disneyland %>%
  select(Review_ID, Review_Text, Rating)%>%
  group_by(Review_ID, Rating)%>%
  unnest_tokens(output = word,input = Review_Text)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(Rating, sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n)) %>%
  ggplot(aes(x=Rating,y=proportion,fill=sentiment))+
  geom_col()+
  theme_economist()+
  coord_flip() +
  labs(title = "Sentiment Analysis of Reviews in Different Rating Categories") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
```
As we could expect, Disney as the "happiest place in the world" received more positive review comments than negative comments. There are both positive and negative words in all rating categories. However, in negative ratings (ratings with a score 1 or 2), there are more negative words used than positive words. And in positive ratings (ratings with a score 4 or 5), there are more positive words used than negative words. This phenomenon make sense.   

We want to see emotions expressed in reviews as well:  
```{r}
#Examine emotions expressed in the reviews:
nrc = read.table(file = 'https://raw.githubusercontent.com/pseudorational/data/master/nrc_lexicon.txt',
                 header = F,
                 col.names = c('word','sentiment','num'),
                 sep = '\t',
                 stringsAsFactors = F)
nrc = nrc[nrc$num!=0,]
nrc$num = NULL

disneyland %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Review_Text)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj() +
  labs(title = "NRC Analysis of ALL Reviews") +
  theme(plot.title = element_text(size = 10, color = "darkgreen"))

library(tidyr)
disneyland %>%
  group_by(Review_ID, Rating)%>%
  unnest_tokens(output = word, input = Review_Text)%>%
  inner_join(nrc)%>%
  group_by(Review_ID,Rating, sentiment)%>%
  count()%>%
  pivot_wider(names_from = sentiment,values_from=n)%>%
  select(Review_ID, Rating, positive, negative, trust, anticipation, joy, fear, anger, sadness, surprise, disgust)%>%
  mutate_at(.vars = 3:12, .funs = function(x) replace_na(x,0))%>%
  ungroup() 
```
There are more than 200,000 positive words used in `Review_Text`, and there are many words express "anticipation", "joy", "trust" feelings in visitors' Disney experience as well. There are about 100,000 negative words used in `Review_Text`, which is less than a half of positive words used. This aligns with our previous observation. We assume "fear", "sadness", "anger", and "disgust" might exist in reviews with lower ratings.   


We built a word cloud to give audience an intuition of the frequency of words used in reviews. 
```{r}
#WordCloud:
#install.packages("wordcloud")
library(wordcloud)
wordcloudData = 
  disneyland %>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  ungroup()%>%
  select(Review_ID,word)%>%
  anti_join(stop_words)%>%
  group_by(word)%>%
  summarize(freq = n())%>%
  arrange(desc(freq))%>%
  ungroup()%>%
  data.frame()

library(wordcloud)
set.seed(617)
wordcloud(words = wordcloudData$word,wordcloudData$freq,scale=c(2,0.5),max.words = 100,colors=brewer.pal(9,"Set2"))
```
```{r}
library(tidyr)
wordcloudData = 
  disneyland %>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word, input = Review_Text)%>%
  ungroup()%>%
  select(Review_ID, word)%>%
  anti_join(stop_words)%>%
  inner_join(get_sentiments('bing'))%>%
  ungroup()%>%
  count(sentiment,word,sort=T)%>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0)%>%
  data.frame()
rownames(wordcloudData) = wordcloudData[,'word']
wordcloudData = wordcloudData[,c('positive','negative')]
set.seed(617)
comparison.cloud(term.matrix = wordcloudData,scale = c(2,0.5),max.words = 200, rot.per=0)
```
Using the above comparison cloud, we can visualize words and sentiment in `Review_Text`.

## Research Question No.1
### Hypothesis 1
In this section, we are going to examine the frequency of top words mentioned by different reviewers come from different continents. 

Ho: Reviewers from different continents focusing on describing the same Disney experience top words.
Ha: Reviewers from different continents focusing on describing different Disney experience top words.

There in total 5 continents where reviewers come from in the dataset. 
```{r}
table(disneyland$continent)
```

Before analyzing focused on different reviewers' continents, We invetigate the top 25 words mentioned by reviewers from all continents to figure out top words that appear commonly among all continents. "park", "disney","disneyland","visit","day","2" are selected to be removed in different continents analysis becasue they have high frequency appeared among all continents and no specific representation. 

#### Top 25 words mentioned by reviewers from all continents
```{r}
disneyland%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(25)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "All continents top words",
       subtitle = "")
```
 
To prepare data, we firstly split dataset based on reviewers' continents into 5 subsets: reviewers from Africa, reviewers from Americas, reviewers from Asia, reviewers from Europe, reviewers from Oceania. 
 
#### Split dataset based on reviewers' continent
```{r}
africa_reviewer <- disneyland %>%
  filter(continent == 'Africa')
americas_reviewer <- disneyland %>%
  filter(continent == 'Americas')
asia_reviewer <- disneyland %>%
  filter(continent == 'Asia')
europe_reviewer <- disneyland %>%
  filter(continent == 'Europe')
oceania_reviewer <- disneyland %>%
  filter(continent == 'Oceania')
```
To analyze different continents' top words frequency, we remove previous selected words without specific meaning and list top 10 words mentioned by reviewers from 5 continents. 

#### Top 10 words mentioned by reviewers from Africa
```{r}
africa_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(10)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Africa top words",
       subtitle = "")
```
 
#### Top 10 words mentioned by reviewers from Americas 
```{r}
americas_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(10)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Americas top words",
       subtitle = "")
```
 
#### Top 10 words mentioned by reviewers from Asia 
```{r}
asia_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(10)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Asia top words",
       subtitle = "")
```
 
#### Top 10 words mentioned by reviewers from Europe 
```{r}
europe_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(10)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Europe top words",
       subtitle = "")
```
 
#### Top 10 words mentioned by reviewers from Oceania 
```{r}
oceania_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(10)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Oceania top words",
       subtitle = "")
```
 
From the above analysis, we can figure out some similarities: 

1. "Rides" and "ride" are among the most frequently mentioned words across all five continents, indicating that amusement parks and similar attractions are popular around the world. 

2. "Time" is frequently mentioned across all continents, suggesting that efficiency and promptness are valued by reviewers globally. 

3. "Kids" is another commonly mentioned word across all continents, indicating that many reviewers visit these attractions with children. 

Also there are differences: 

1. "Food" is a frequently mentioned word in Africa, Asia, Europe, and Oceania, suggesting that food options and quality are an important aspect of the overall experience for reviewers from these continents. 

2. Topic words about queuing and waiting ("queues","queue", "lines", "wait") are mentioned in Africa, Americas, Europe, and Oceania, and none of these words are mentioned in Asia.This could indicate that there are differences in the theme or experience of queuing or waiting in amusement parks or related attractions between these regions. 

3. Topic words about Disneyland's special events ("Parade", "Fireworks") in Africa and Asia.It may indicate that Disneyland's parades and fireworks shows are a unique and important aspect of the park's experience for visitors from these continents. Meanwhile, the absence of these words in the top word lists for Europe and the Americas may suggest that these special events are relatively less important or less prominent in those regions, or that visitors from those regions have different expectations or preferences when it comes to amusement park experiences. 

### Hypothesis 2 
In this section, we are going to examine the proportion of reviews that mention car adventure related words. 

Ho: Reviewers from America and Canada mention car adventures in their reviews at the same or less frequency as reviewers from other countries. 
Ha: Reviewers from America and Canada mention car adventure in their reviews more frequently than others.

#### 1. Prepare Data
##### Split dataset based on reviewer country/continent
To prepare data, we firstly split dataset based on reviewers' countries into reviewers in America and Canada and reviewers in other countries (expect America and Canada). 
```{r}
ac_reviewer <- disneyland %>%
  filter(Reviewer_Location %in% c('United States', 'Canada'))
ac_other_reviewer <- disneyland %>%
  filter(!Reviewer_Location %in% c('United States', 'Canada'))
```

##### Create corpus
```{r}
corpus_ac = Corpus(VectorSource(ac_reviewer$Review_Text))
corpus_ac_other = Corpus(VectorSource(ac_other_reviewer$Review_Text))
```

##### Convert text to lower case
```{r}
corpus_ac = tm_map(corpus_ac,FUN = content_transformer(tolower))
corpus_ac_other = tm_map(corpus_ac_other,FUN = content_transformer(tolower))
```

#### 2. Data Explore
We draw a TF-IDF diagram to visualize frequncy of top 25 words based on different groups of reviewers. 
##### Top 25 words mentioned by reviewers from America and Canada
```{r}
ac_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(25)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "America and Canada top words",
       subtitle = "")
```
 
##### Top 25 words mentioned by reviewers from other countries except America and Canada
```{r}
ac_other_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(25)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Other countries except America and Canada top words",
       subtitle = "")
```

#### 3. America & Canada car related words frequency and sentiment analysis

##### Frequency analysis
To analyze car related words frequency in American and Canadian reviewers, we begin with picking key words for retained car related words. Directly car related words include: "car","vehicle". We also include names of rides with car concepts in Disneyland: Radiator Springs Racers, Autopia, and Luigi Rollickin Roadsters. 

##### Retain car related words only
```{r}
car_words <- c(
  'car', 'vehicle',
  'radiator','springs','racers','autopia',
  'luigi','rollickin','roadsters')
```

```{r}
corpus <- corpus_ac
corpus = tm_map(corpus,FUN = removePunctuation)
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus = tm_map(corpus,FUN = stripWhitespace)

corpus = tm_map(corpus,FUN = stemDocument)
dtm_ac <- DocumentTermMatrix(corpus)
words_remove <- setdiff(colnames(dtm_ac), car_words)
length(words_remove)
```

```{r}
corpus = tm_map(corpus, FUN = removeWords, words_remove[1:4000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[4001:7000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[7001:10000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[10001:13000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[13001:16000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[16001:19000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[19001:22000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[22001:23933])

corpus = tm_map(corpus, FUN = removeNumbers)
```

```{r}
# transform to document term matrix
dtm_ac_then <- DocumentTermMatrix(corpus)
colnames(dtm_ac_then)
# make data frame
dtm_ac_then = as.data.frame(as.matrix(dtm_ac_then))
sort(colSums(dtm_ac_then),decreasing = T)
# add a column counting the number of car related words in a review
dtm_ac_then['car_word_count'] = rowSums(dtm_ac_then)
# add a column specifying if a review contains car related words
dtm_ac_then['if_car_word'] = ifelse(dtm_ac_then$car_word_count >= 1, 1, 0)
# percentage of car related reviews
sum(dtm_ac_then$if_car_word) / nrow(dtm_ac_then) #0.0569766
```

#### Sentiment Analysis
```{r}
ac_new = cbind(ac_reviewer, dtm_ac_then)
ac_car_sentiment = ac_new %>% filter(if_car_word ==1)
```

##### Clean the text
```{r}
# Convert to lower case
ac_car_sentiment$Review_Clean <- tolower(ac_car_sentiment$Review_Text)

# Remove Stopwords
ac_car_sentiment$Review_Clean <- lapply(strsplit(ac_car_sentiment$Review_Clean, "\\s+"), function(x) paste(x[!x %in% stopwords('english')], collapse = " "))
ac_car_sentiment$Review_Clean <- unlist(ac_car_sentiment$Review_Clean)
```


```{r}
afinn = get_sentiments('afinn')

ac_car_sentiment %>%
  select(Review_ID,Review_Clean)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Clean)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  summarize(min=min(reviewSentiment),
            max=max(reviewSentiment),
            median=median(reviewSentiment),
            mean=mean(reviewSentiment))
#1.411412
```

#### 4. Other countires except America & Canada car related words frequency analysis
```{r}
corpus <- corpus_ac_other
corpus = tm_map(corpus,FUN = removePunctuation)
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus = tm_map(corpus,FUN = stripWhitespace)

corpus = tm_map(corpus,FUN = stemDocument)
dtm_ac_other <- DocumentTermMatrix(corpus)
words_remove <- setdiff(colnames(dtm_ac_other), car_words)
length(words_remove)
```

```{r}
corpus = tm_map(corpus, FUN = removeWords, words_remove[1:4000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[4001:7000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[7001:10000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[10001:13000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[13001:16000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[16001:19000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[19001:22000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[22001:25000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[25001:28000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[28001:31000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[31001:34000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[34001:37000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[37001:40000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[40001:43000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[43001:43742])

corpus = tm_map(corpus, FUN = removeNumbers)
```

```{r}
# transform to document term matrix
dtm_ac_other_then <- DocumentTermMatrix(corpus)
colnames(dtm_ac_other_then)
# make data frame
dtm_ac_other_then = as.data.frame(as.matrix(dtm_ac_other_then))
sort(colSums(dtm_ac_other_then),decreasing = T)
# add a column counting the number of car related words in a review
dtm_ac_other_then['car_word_count'] = rowSums(dtm_ac_other_then)
# add a column specifying if a review contains car related words
dtm_ac_other_then['if_car_word'] = ifelse(dtm_ac_other_then$car_word_count >= 1, 1, 0)
# percentage of car related reviews
sum(dtm_ac_other_then$if_car_word) / nrow(dtm_ac_other_then) #0.04708052
```
The proportion of car adventure related words mentioned in American and Canadian reviewers' reviews is 0.0569766, while the proportion of car adventure related words mentioned in other countries (except America and Canadia) reviewers' reviews is 0.04708052. It is indicated that American and Canadian reviewers' frequency of mentioning car adventure related words is 0.989608% higher than other countries. 

The effect size is greater than the set threshold of 0.5%, and the null hypothesis is rejected. It means that reviewers from America and Canada mention car adventure in their reviews more frequently than others.It indicates that when American and Canadian reviewers do mention car adventure in their reviews, they tend to have a positive sentiment towards it, with an average sentiment score of 1.411412. 

### Hypothesis 3 
In this section, we are going to examine the proportion of reviews that mention food-related words. 

Ho: Reviewers from Asian countries mention food in the reviews at the same or less frequency as reviewers from other continents. 
Ha: Reviewers from Asian countries mention food in their reviews more frequently than reviewers from other continents. 

#### 1. Prepare Data
##### Split dataset based on reviewer continent
To prepare data, we firstly split dataset based on reviewers' continents into reviewers in Asian and reviewers in other continents expect Asia. 
```{r}
asian_reviewer <- disneyland %>%
  filter(continent == 'Asia')
asian_other_reviewer <- disneyland %>%
  filter(continent != 'Asia')
```
##### Create corpus
```{r}
corpus_asian = Corpus(VectorSource(asian_reviewer$Review_Text))
corpus_asia_other = Corpus(VectorSource(asian_other_reviewer$Review_Text))
```

##### Convert text to lower case
```{r}
corpus_asian = tm_map(corpus_asian,FUN = content_transformer(tolower))
corpus_asia_other = tm_map(corpus_asia_other,FUN = content_transformer(tolower))
```

#### 2. Data Explore
##### Top 15 words mentioned by reviewers from Asia
```{r}
asian_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(15)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Asian countries top words",
       subtitle = "")
```
 
##### Top 15 words mentioned by reviewers from continents other than Asia
```{r}
asian_other_reviewer%>%
  unnest_tokens(input = Review_Text, output = word)%>%
  select(word)%>%
  anti_join(stop_words)%>%
  filter(!word %in% c("disneyland", "disney", "park", "visit", "day", "2")) %>%
  group_by(word)%>%
  summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%
  top_n(15)%>%
  ggplot(aes(x=reorder(word,count), y=count, fill=count))+
    geom_col()+
    xlab('words')+
    coord_flip()+
    labs(x = "Top words",
       y = "Frequency",
       title = "Non-Asian countries top words",
       subtitle = "")
```
After filtering out the common mentioned words, we can see from the charts that both Asian and non-Asian reviewers include a lot of 'food' words in their reviews. Asian reviewers also mention a lot of 'Hong Kong' related words which is located in Asia, this implies that visitors may tend to visit the Disney theme parks near where they are located. 
 
'Time' and 'Wait' also appears a lot in both Asian and non-Asian reviewers' reviews, which implies that the visitors care a lot about the wait times.

#### 3. Asia food related words frequency analysis 

#### Frequency analysis
To analyze food related words frequency in Asian reviewers, we begin with picking a list of food related words that are related to Disneyland. 

##### Retain food related words only
```{r}
food_words <- c(
  'food','foods',
  'eating','eat','ate',
  'restaurant',
  'meals','drink','snack','churro','cake',
  'Turkey','corn','popcorn','pretzel','pizza','taco',
  'burger','sandwiches','milkshakes','rice','fries',
  'chicken','beef','pork',
  'beer','wine',
  'breakfast','lunch','dinner')
```

##### Clean Asian food reviews
```{r}
# Clean the text
corpus <- corpus_asian
corpus = tm_map(corpus,FUN = removePunctuation)
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus = tm_map(corpus,FUN = stripWhitespace)

corpus = tm_map(corpus,FUN = stemDocument)
dtm_asian <- DocumentTermMatrix(corpus)
words_remove <- setdiff(colnames(dtm_asian), food_words)
length(words_remove)
```

```{r}
# Retain food related words only
corpus = tm_map(corpus, FUN = removeWords, words_remove[1:4000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[4001:7000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[7001:10000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[10001:13000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[13001:16000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[16001:16006])

corpus = tm_map(corpus, FUN = removeNumbers)
```


##### Calculate the proportion of food related words mentioned in Asian reviewers' reviews
```{r}
# Transform to document term matrix
dtm_asian_then <- DocumentTermMatrix(corpus)
colnames(dtm_asian_then)
# make data frame
dtm_asian_then = as.data.frame(as.matrix(dtm_asian_then))
sort(colSums(dtm_asian_then),decreasing = T)
# add a column counting the number of food related words in a review
dtm_asian_then['food_word_count'] = rowSums(dtm_asian_then)
# add a column specifying if a review contains food related words
dtm_asian_then['if_food_word'] = ifelse(dtm_asian_then$food_word_count >= 1, 1, 0)
# percentage of food related reviews
sum(dtm_asian_then$if_food_word) / nrow(dtm_asian_then)      
```
 
#### 4. Non-Asia food related words frequency analysis
##### Clean Non-Asian food reviews
```{r}
# Clean the text
corpus <- corpus_asia_other
corpus = tm_map(corpus,FUN = removePunctuation)
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus = tm_map(corpus,FUN = stripWhitespace)

corpus = tm_map(corpus,FUN = stemDocument)
dtm_asia_other <- DocumentTermMatrix(corpus)
words_remove <- setdiff(colnames(dtm_asia_other), food_words)
length(words_remove)
```

```{r}
# Retain food related words only
corpus = tm_map(corpus, FUN = removeWords, words_remove[1:4000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[4001:7000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[7001:10000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[10001:13000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[13001:16000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[16001:19000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[19001:22000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[22001:25000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[25001:28000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[28001:31000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[31001:34000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[34001:37000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[37001:40000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[40001:43000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[43001:46000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[46001:48705])

corpus = tm_map(corpus, FUN = removeNumbers)
```

##### Calculate the proportion of food related words mentioned in non-Asian reviewers' reviews
```{r}
# transform to document term matrix
dtm_asia_other_then <- DocumentTermMatrix(corpus)
colnames(dtm_asia_other_then)

# make data frame
dtm_asia_other_then = as.data.frame(as.matrix(dtm_asia_other_then))
sort(colSums(dtm_asia_other_then),decreasing = T)
# add a column counting the number of food related words in a review
dtm_asia_other_then['food_word_count'] = rowSums(dtm_asia_other_then)
# add a column specifying if a review contains food related words
dtm_asia_other_then['if_food_word'] = ifelse(dtm_asia_other_then$food_word_count >= 1, 1, 0)
# percentage of food related reviews
sum(dtm_asia_other_then$if_food_word) / nrow(dtm_asia_other_then)   
```
The proportion of food-related words mentioned in Asian reviewers' reviews is 0.2843093, while the proportion of food-related words mentioned in non-Asian reviewers' reviews is 0.3446041, which is 6% higher than Asian reviewers. Therefore, we fail to reject the null hypothesis, it means that reviewers from Asian countries does not mention food more frequently than reviewers from non-Asian countries. This implies that Asian visitors may care less about food than visitors from non-Asian countries do when they visit the Disney theme parks.


#### 5. Sentiment Analysis - Asia food related reviews
In this section, we will analyze Asian reviewers's sentiments when they mention about food in their reviews.
```{r}
asia_new = cbind(asian_reviewer, dtm_asian_then)
asia_food_sentiment = asia_new %>% filter(if_food_word ==1)
```

##### Clean the text
```{r}
# Convert to lower case
asia_food_sentiment$Review_Clean <- tolower(asia_food_sentiment$Review_Text)

# Remove Stopwords
asia_food_sentiment$Review_Clean <- lapply(strsplit(asia_food_sentiment$Review_Clean, "\\s+"), function(x) paste(x[!x %in% stopwords('english')], collapse = " "))
asia_food_sentiment$Review_Clean <- unlist(asia_food_sentiment$Review_Clean)
```

##### Explore the sentiment score
```{r}
afinn = get_sentiments('afinn')

asia_food_sentiment %>%
  select(Review_ID,Review_Clean)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Clean)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  summarize(min=min(reviewSentiment),
            max=max(reviewSentiment),
            median=median(reviewSentiment),
            mean=mean(reviewSentiment))
```
The average sentiment score of Asian reviewers when they mention about food in their reviews is 1.53. We can know that even Asian reviewers may not care about food as much as other reviewers do, they are overall satisfied about the food in the Disney theme parks they visited.

## Research Question No.2
### Hypothesis 1:   
```{r}
library(grid)
library(gridExtra)
```


Ho: Reviews from different Disney branches tend to focus on similar topics.  
Ha: Reviews from different Disney branches focus on different topics. 

```{r, warning=FALSE}
# split dataset based on branch
hongkong <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong')
cali <- disneyland %>%
  filter(Branch == 'Disneyland_California')
paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris')
```       
Splited the three branches based on location and examine the reviews in the following.


#### Hong Kong       
```{r, warning=FALSE}
hongkong$Review_Text <- gsub('Hong Kong','HongKong', hongkong$Review_Text)

# create corpus
corpus = Corpus(VectorSource(hongkong$Review_Text))
corpus[[1]][1]

# clean text
# convert to lower case
corpus = tm_map(corpus,FUN = content_transformer(tolower))

# remove urls
corpus = tm_map(corpus,
                FUN = content_transformer(FUN = function(x)gsub(pattern = 'http[[:alnum:][:punct:]]*',
                                                                replacement = ' ',x = x)))

# remove punctuations
corpus = tm_map(corpus,FUN = removePunctuation)
corpus[[1]][1]

# remove stopwords
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus[[1]][1]

# strip white spaces
corpus = tm_map(corpus,FUN = stripWhitespace)
corpus[[1]][1]

# create dictionary
dict = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(disneyland$Review_Text))),
                     lowfreq = 0)
dict_corpus = Corpus(VectorSource(dict))

# stem document
corpus = tm_map(corpus,FUN = stemDocument)

# create document term matrix
dtm = DocumentTermMatrix(corpus)

# remove sparse terms
xdtm = removeSparseTerms(dtm,sparse = 0.97)
xdtm
dim(xdtm)

# make dataframe and complete stems
xdtm = as.data.frame(as.matrix(xdtm))
colnames(xdtm) = stemCompletion(x = colnames(xdtm),
                                dictionary = dict_corpus,
                                type='prevalent')
colnames(xdtm) = make.names(colnames(xdtm))
word_freq_hk <- data.frame(word = colnames(xdtm), freq = colSums(xdtm))


# word cloud
# set.seed(617)
# wordcloud(words = word_freq_hk$word,word_freq_hk$freq,scale=c(2,0.5),max.words = 100,colors=brewer.pal(9,"Spectral"))



word_total_hk = sum(word_freq_hk$freq)
hk_30 <- word_freq_hk %>%
  mutate(percentage = freq/word_total_hk*100) %>%
  arrange(desc(percentage)) %>%
  head(30)

# top 30 frequent words in Hong Kong
hk_30


#hk_30%>%
#  ggplot(aes(x=reorder(word,percentage), y=percentage, fill=percentage))+
#  geom_col(position='dodge')+
#  coord_flip()+
#  scale_fill_gradient2(low ="#FFEDF0", high = "#C84747",space ="Lab", guide = FALSE) + 
#  theme_economist()+
#  theme(plot.background = element_blank()) 
```       
The above result shows the top 30 frequent words in Hong Kong branch. There are words that are very common in this scenario but do not convey useful information, like 'disneyland', 'disney', 'one', and verbs like 'get', 'can', 'will', etc. Therefore, by manually filtering words that might convey more meaningful information, we would be able to know what topics do the reviewer care about when they visit to each branch. 


##### Selected top 10 topics in Hong Kong       

```{r, warning=FALSE, fig.width=12, fig.height=6}
hk_topwords <- subset(hk_30, rownames(hk_30) %in% c("ride", "park", "kid", "show", 'hongkong',
                                                    "food", "parad", "queue", "firework", "wait")) # 10 word
hk_topwords%>%
  ggplot(aes(x=reorder(word,percentage), y=percentage, fill=percentage))+
  geom_col(position='dodge')+
  coord_flip()+
  scale_fill_gradient2(low ="#FFEDF0", high = "#C84747",space ="Lab", guide = FALSE) + 
  theme_economist()+
  theme(plot.background = element_blank()) +
  labs(x = "Words", y = "Frequency in %") +
  ggtitle("Top 10 frequent topics in Hong Kong with % distribution")
```           
  
Above are the selected top 10 topics with frequency percentages for Hong Kong branch. We noticed that a considerable proportion of reviewers care about ride, the park itself, care about kid, the shows, etc. Looks like people tend to be excited about the Hong Kong branch itself. Following by food, parade, the queue and wait, as well as the firework. Looks like the top topics generally cover most of the facilities that are included in a typical Disneyland park.           
Next, we would use the same process to first generate top 30 frequent words for California branch and Paris branch, and then manually select meaningful topics that can provide insights.


#### California        

```{r, results = "hide", warning=FALSE}
# create corpus
corpus = Corpus(VectorSource(cali$Review_Text))
corpus[[1]][1]

# clean text
# convert to lower case
corpus = tm_map(corpus,FUN = content_transformer(tolower))

# remove urls
corpus = tm_map(corpus,
                FUN = content_transformer(FUN = function(x)gsub(pattern = 'http[[:alnum:][:punct:]]*',
                                                                replacement = ' ',x = x)))

# remove punctuations
corpus = tm_map(corpus,FUN = removePunctuation)
corpus[[1]][1]

# remove stopwords
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus[[1]][1]

# strip white spaces
corpus = tm_map(corpus,FUN = stripWhitespace)
corpus[[1]][1]

# create dictionary
dict = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(disneyland$Review_Text))),
                     lowfreq = 0)
dict_corpus = Corpus(VectorSource(dict))

# stem document
corpus = tm_map(corpus,FUN = stemDocument)

# create document term matrix
dtm = DocumentTermMatrix(corpus)

# remove sparse terms
xdtm = removeSparseTerms(dtm,sparse = 0.97)
xdtm
dim(xdtm)

# make dataframe and complete stems
xdtm = as.data.frame(as.matrix(xdtm))
colnames(xdtm) = stemCompletion(x = colnames(xdtm),
                                dictionary = dict_corpus,
                                type='prevalent')
colnames(xdtm) = make.names(colnames(xdtm))
word_freq_cali <- data.frame(word = colnames(xdtm), freq = colSums(xdtm))

# word cloud
# set.seed(617)
# wordcloud(words = word_freq_cali$word,word_freq_cali$freq,scale=c(2,0.5),max.words = 100,colors=brewer.pal(9,"Spectral"))

word_total_ca = sum(word_freq_cali$freq)
ca_30 <- word_freq_cali %>%
  mutate(percentage = freq/word_total_ca*100) %>%
  arrange(desc(percentage)) %>%
  head(30)
```

```{r, warning=FALSE, fig.width=12, fig.height=6}
# top 30 frequent topics in California
ca_30

#ca_30%>%
#  ggplot(aes(x=reorder(word, percentage), y=percentage, fill=percentage))+
#  geom_col(position='dodge')+
#  coord_flip()+
#  scale_fill_gradient2(low ="#D6F1DF", high = "#00A632",space ="Lab", guide = FALSE) + 
#  theme_economist()+
#  theme(plot.background = element_blank()) 
```

##### Selected top 10 topics in California       

```{r, warning=FALSE}
ca_topwords <- subset(ca_30, rownames(ca_30) %in% c("park", "ride", "line", "pass", "wait",
                                                    "kid", "crowd", "fast", "peopl", "back")) # 10 words
ca_topwords %>%
  ggplot(aes(x=reorder(word, percentage), y=percentage, fill=percentage))+
  geom_col(position='dodge')+
  coord_flip()+
  scale_fill_gradient2(low ="#D6F1DF", high = "#00A632",space ="Lab", guide = FALSE) + 
  theme_economist()+
  theme(plot.background = element_blank()) +
  labs(x = "Words", y = "Frequency in %") +
  ggtitle("Top 10 frequent topics in California with % distribution")

```               

Above is the top 10 most frequent topics in California branch. Comparing to the Hong Kong branch, we could easily see that words like 'line', 'pass', 'crowd', 'fast', and 'people' occured on the list. This might suggest that people have more to say about their queue experiences, waiting time, about the visiting crowd or visitor amount, and probably the speed and efficiency taking rides during their visits.         


#### Paris          

```{r, results = "hide", warning=FALSE}
# create corpus
corpus = Corpus(VectorSource(paris$Review_Text))
corpus[[1]][1]

# clean text
# convert to lower case
corpus = tm_map(corpus,FUN = content_transformer(tolower))

# remove urls
corpus = tm_map(corpus,
                FUN = content_transformer(FUN = function(x)gsub(pattern = 'http[[:alnum:][:punct:]]*',
                                                                replacement = ' ',x = x)))

# remove punctuations
corpus = tm_map(corpus,FUN = removePunctuation)
corpus[[1]][1]

# remove stopwords
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus[[1]][1]

# strip white spaces
corpus = tm_map(corpus,FUN = stripWhitespace)
corpus[[1]][1]

# create dictionary
dict = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(paris$Review_Text))),
                     lowfreq = 0)
dict_corpus = Corpus(VectorSource(dict))

# stem document
corpus = tm_map(corpus,FUN = stemDocument)

# create document term matrix
dtm = DocumentTermMatrix(corpus)

# remove sparse terms
xdtm = removeSparseTerms(dtm,sparse = 0.97)
xdtm
dim(xdtm)

# make dataframe and complete stems
xdtm = as.data.frame(as.matrix(xdtm))
colnames(xdtm) = stemCompletion(x = colnames(xdtm),
                                dictionary = dict_corpus,
                                type='prevalent')
colnames(xdtm) = make.names(colnames(xdtm))
word_freq_paris <- data.frame(word = colnames(xdtm), freq = colSums(xdtm))

# wordcloud
#set.seed(617)
#wordcloud(words = word_freq_paris$word,word_freq_paris$freq,scale=c(2,0.5),max.words = 100,colors=brewer.pal(9,"Spectral"))

word_total_pr = sum(word_freq_paris$freq)
pr_30 <- word_freq_paris %>%
  mutate(percentage = freq/word_total_ca*100) %>%
  arrange(desc(percentage)) %>%
  head(30)
```

```{r, warning=FALSE}
# top 30 frequent topics in Paris
pr_30

#pr_30%>%
#  ggplot(aes(x=reorder(word, percentage), y=percentage, fill=percentage))+
#  geom_col(position='dodge')+
#  coord_flip()+
#  scale_fill_gradient2(low ="#D4DFFF", high = "#4169E2",space ="Lab", guide = FALSE) + 
#  theme_economist()+
#  theme(plot.background = element_blank())
```

##### Selected top 10 topics in Paris       

```{r, warning=FALSE, fig.width=12, fig.height=6}
pr_topwords <- subset(pr_30, rownames(pr_30) %in% c(1, 2, 8, 13, 14, 
                                                    15, 18, 21, 27, 28)) # 10 words
pr_topwords %>%
  ggplot(aes(x=reorder(word, percentage), y=percentage, fill=percentage))+
  geom_col(position='dodge')+
  coord_flip()+
  scale_fill_gradient2(low ="#D4DFFF", high = "#4169E2",space ="Lab", guide = FALSE) + 
  theme_economist()+
  theme(plot.background = element_blank()) +
  labs(x = "Words", y = "Frequency in %") +
  ggtitle("Top 10 frequent topics in Paris with % distribution")



```               

Above is the top 10 most frequent topics in Paris branch. Comparing to the previous two branches, reviewers also mentioned a lot about 'queue', 'food', 'wait', 'show', 'parade', and 'kid'. However, what's worth noticing is that they also mentioned a lot about 'pariah' and 'character', which are new to the other two branches.           


```{r}
head(paris[grep("pariah", paris$Review_Text, ignore.case = TRUE), "Review_Text"], 2)
head(paris[grep("character", paris$Review_Text, ignore.case = TRUE), "Review_Text"], 2)
```               
Taking closer look at the reviews, we noticed that the reviewer who mentioned 'pariah' mostly talked about how they were treated like 'pariah' in some cases, some suggested otherwise. This might suggest that the customer services might be considered as polarized. For the 'character' word, this might suggest that visitors who went to Paris branch pay considerable attention to meeting with the characters in the park.        



#### Same frequent topics in all three branches

```{r, warning=FALSE, fig.width=12, fig.height=6}
hk_sub <- filter(hk_topwords, 
                 word %in% c('park', 'ride', 'wait', 'kid'))%>% mutate(branch = 'hk')

ca_sub <- filter(ca_topwords, 
                 word %in% c('park', 'ride', 'wait', 'kid'))%>% mutate(branch = 'ca')

pr_sub <- filter(pr_topwords, 
                 word %in% c('park', 'ride', 'wait', 'kid'))%>% mutate(branch = 'pr')

same_topwords = rbind(hk_sub, ca_sub, pr_sub)
same_topwords <- same_topwords %>%
  select(word, percentage, branch)

ggplot(same_topwords, aes(x = word, y = percentage, fill = branch)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ branch, ncol = 3) +
  labs(x = "Words", y = "Percentages in %", fill = "Branch") +
  theme(plot.background = element_blank(),
        #text=element_text(size=16),
        strip.text=element_text(size=14),
        axis.text.x=element_text(size=14, angle=45, hjust=1),
        axis.text.y=element_text(size=14),
        legend.position = "none") +
  scale_fill_manual(values = c("hk" = "#EE4242", "ca" = "#28E92C", "pr" = "#4169E2", guide = FALSE)) +
  ggtitle("Same frequent words/topics in all three branches")

```               
          
          
These words, 'kid', 'park', 'ride', and 'wait' are topics that are mentioned for all three branches. These might suggest that reviewers care about these topics regardless of the branch locations.         


### Hypothesis 2:  
```{r, echo=FALSE, message = F, results = "hide", warning=FALSE}
disneyland<- read.csv(file = "disneyland.csv", stringsAsFactors = F)
rides <- read_csv('rides.csv')
```

Ho: Hong Kong Disneyland receives reviews related to shopping experiences in similar proportion as other branches.  
Ha: Hong Kong Disneyland receives reviews related to shopping experiences in different proportion as other branches.  

```{r}
# examine branch names
unique(disneyland$Branch)
```

Split dataset based on branch

```{r}
hongkong <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong')
cali <- disneyland %>%
  filter(Branch == 'Disneyland_California')
paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris')
```

Check document integrity
```{r}
nrow(disneyland) == nrow(hongkong) + nrow(cali) + nrow(paris)
```


Create corpus based on branches:
```{r, warning=FALSE}
corpus_hk = Corpus(VectorSource(hongkong$Review_Text))
corpus_cali = Corpus(VectorSource(cali$Review_Text))
corpus_paris = Corpus(VectorSource(paris$Review_Text))
```

#### Hong Kong

Define shopping-related words:
```{r, warning=FALSE}
shopping_words <- c(
  'shop',
  'souvenir',
  'merchandise',
  'collectible',
  'gift',
  'shirt',
  'toy',
  'book',
  'hat',
  'band',
  'art', 'mall', 'cashier', 'cloth', 'checkout', 'cart', 'outlet', 'bag', 'quality', 'boutique'
)
```



Cleaning texts:
```{r warning=FALSE}
corpus <- corpus_hk
# convert to lower cases
corpus = tm_map(corpus,FUN = content_transformer(tolower))
# remove punctuations
corpus = tm_map(corpus,FUN = removePunctuation)
# remove stopwords
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
# stripwhitespaces
corpus = tm_map(corpus,FUN = stripWhitespace)
# stem the corpurs
corpus = tm_map(corpus,FUN = stemDocument)
# convert corpus to document term matrix to get a list of unique words contained in all reviews
dtm_hk <- DocumentTermMatrix(corpus)
# select words unrelated to shopping to be removed
words_remove <- setdiff(colnames(dtm_hk), shopping_words)
length(words_remove)
# remove words unrelated to shopping
corpus = tm_map(corpus, FUN = removeWords, words_remove[1:4000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[4001:7000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[7001:10000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[10001:13000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[13001:16000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[16001:17987])
corpus = tm_map(corpus, FUN = removeNumbers)
```

Transform cleaned corpus to document term matrix
```{r, warning=FALSE}
dtm_hk_then <- DocumentTermMatrix(corpus)
colnames(dtm_hk_then)
```


Make data frame
```{r, warning=FALSE}
dtm_hk_then = as.data.frame(as.matrix(dtm_hk_then))
sort(colSums(dtm_hk_then),decreasing = T)

```

Add information summarizing columns:
```{r, warning=FALSE, fig.width=12, fig.height=6}
# add a column counting the number of shopping related words in a review
dtm_hk_then['shopping_word_count'] = rowSums(dtm_hk_then)
# add a column specifying if a review contains shopping related words
dtm_hk_then['if_shopping_word'] = ifelse(dtm_hk_then$shopping_word_count >= 1, 1, 0)
```

Attach word frequency to original data frame and select columns
```{r, warning=FALSE, fig.width=12, fig.height=6}
hongkong <- hongkong %>%
  cbind(dtm_hk_then) %>%
  select(-Review_ID, -Reviewer_Location, 
         -Review_Text, -Year_Month, 
         -Year, -Month, -continent)
hongkong['no_shopping_word'] = ifelse(rowSums(hongkong[4:19]) == 0, 1, 0)
hongkong <- hongkong %>%
  select_if(function(x) !all(x == 0))
```

Calculate average ratings for each shopping words and add counts
```{r, warning=FALSE, fig.width=12, fig.height=6}
shopping_hk = data.frame(rd=names(colSums(hongkong[c(4:22)])))
df <- data.frame()
for (i in 1:nrow(shopping_hk)) { 
  for (k in shopping_hk[i,]) { 
    avg_rating <- hongkong %>%
      filter(hongkong[,k] != 0) %>%
      summarise(avg_rating = mean(Rating))
    df <- rbind(df, avg_rating)
  } 
}
shopping_mention_count <- data.frame(rides = names(colSums(hongkong[c(4:22)])), 
                                 counts = as.numeric(colSums(hongkong[c(4:22)])),
                                 avg_raing = df)
shopping_mention_count
```

Get frequency of each shopping word in total branch reviews & in reviews that mentioned shopping in the branch
```{r, warning=FALSE, fig.width=12, fig.height=6}
freq_all <- shopping_mention_count %>%
  mutate(freq_branch_pct = counts/nrow(hongkong)*100, 
         freq_Mention_pct = counts/counts[17]*100) %>%
  mutate_at(c(3:5), round, digits = 2)%>%
  arrange(desc(freq_Mention_pct))
freq_all
```


##### Rating analysis


Proportions of reviews that mentioned shopping words & no mention rides in the branch
```{r, warning=FALSE, fig.width=12, fig.height=6}
p_mention_orno <- freq_all[c(1,3), 1:4]
p_mention_orno%>%
  ggplot(aes(x="", y=freq_branch_pct, fill=rides)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  labs(fill = "Shopping Words Mentioned") +
  ggtitle("Reviews that mentioned & did not mention shopping words in Hong Kong Branch") +
  theme_void()+
  geom_text(aes(label = paste0(freq_branch_pct, "%")), position = position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#F1786C", "#E8CCC7"), 
                    labels=c("Mentioned", "Did not mention"))
```




Proportions of shopping words mentioned in the branch over total number of reviews in the branch & over reviews that mentioned rides in branch
```{r, warning=FALSE, fig.width=12, fig.height=6}
p_shops <- freq_all[4:19, 1:5]

# filter freqs >= 2% of the reviews that mentioned rides in the branch, rating high to low
hot_shops <- p_shops %>%
  filter(freq_Mention_pct >= 2) 

shopping_rank_plot <- hot_shops%>%
  ggplot(aes(x=reorder(rides,freq_Mention_pct), 
             y=freq_Mention_pct, fill=freq_Mention_pct))+
  geom_col(position='dodge')+
  coord_flip()+
  labs(x = "", y = "Frequency in %") +
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(0, 30)) +
  ggtitle("All shopping words mentioned in Hong Kong with % distribution")+
  scale_fill_gradient(low = "#FCDADA", high = "#C50F0F", guide = FALSE) +
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.x  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"), 
        plot.title = element_text(size = 20), 
        axis.text.x = element_text(size = 15), 
        axis.text.y = element_text(size = 15))

rating_rank_plot <- hot_shops %>%
  ggplot() +
  geom_col(aes(x=reorder(rides, -avg_rating), y=freq_Mention_pct, fill=freq_Mention_pct), 
           width=0.7, position='dodge')+  
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(-3, 30)) +
  geom_text(aes(x=rides, y=-1.5, label=avg_rating), size = 5) +
  labs(x = "Mostly mentioned shopping words", y = "Frequency in %") +
  ggtitle("Average rating ranked with most popular shopping words & no shopping words") +
  scale_fill_gradient(low = "#FCDADA", high = "#C50F0F", guide = FALSE)+
  labs(tag ="Ratings:")+  
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.y  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.tag.position = c(0.01,0.12),
        plot.tag = element_text(hjust = 0, size=13),
        plot.title = element_text(size = 20), 
        axis.text.x = element_text(size = 15), 
        axis.text.y = element_text(size = 13))

#grid.arrange(shopping_rank_plot, rating_rank_plot, ncol = 2)
shopping_rank_plot
rating_rank_plot
```

From the two graphs above, we can see that words including "shop", "toy", "book" and "souvenir" are mentioned most frequently in reviews of the Hong Kong brancn, indicating the most cared aspects of shopping. Products like book, cloth and toy received higher ratings while cart, bag hat received lower ratings also implies customer satisfaction. 



#### California

Cleaning texts:
```{r, message=FALSE, warning=FALSE}
corpus <- corpus_cali
corpus = tm_map(corpus,FUN = content_transformer(tolower))
corpus = tm_map(corpus,FUN = removePunctuation)
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus = tm_map(corpus,FUN = stripWhitespace)
corpus = tm_map(corpus,FUN = stemDocument)
dtm_cali <- DocumentTermMatrix(corpus)
words_remove <- setdiff(colnames(dtm_cali), shopping_words)
length(words_remove)

corpus = tm_map(corpus, FUN = removeWords, words_remove[1:4000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[4001:7000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[7001:10000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[10001:13000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[13001:16000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[16001:19000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[19001:21000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[21001:24000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[24001:25632])
corpus = tm_map(corpus, FUN = removeNumbers)
```



Transform cleaned corpus to document term matrix
```{r, warning=FALSE}
dtm_cali_then <- DocumentTermMatrix(corpus)
colnames(dtm_cali_then)
```


Make data frame
```{r, warning=FALSE}
dtm_cali_then = as.data.frame(as.matrix(dtm_cali_then))
sort(colSums(dtm_cali_then),decreasing = T)
```
Add information summarizing columns:
```{r, warning=FALSE}
# add a column counting the number of shopping related words in a review
dtm_cali_then['shopping_word_count'] = rowSums(dtm_cali_then)
# add a column specifying if a review contains shopping related words
dtm_cali_then['if_shopping_word'] = ifelse(dtm_cali_then$shopping_word_count >= 1, 1, 0)
```

Attach word frequency to original data frame and select columns
```{r, warning=FALSE}
cali <- cali %>%
  cbind(dtm_cali_then) %>%
  select(-Review_ID, -Reviewer_Location, 
         -Review_Text, -Year_Month, 
         -Year, -Month, -continent)
cali['no_shopping_word'] = ifelse(rowSums(cali[4:19]) == 0, 1, 0)
cali <- cali %>%
  select_if(function(x) !all(x == 0))
```


Calculate average ratings for each shopping words and add counts
```{r, warning=FALSE}
shopping_ca = data.frame(rd=names(colSums(cali[c(4:22)])))
# average rating for each shopping word
df <- data.frame()
for (i in 1:nrow(shopping_ca)) { 
  for (k in shopping_ca[i,]) { 
    avg_rating <- cali %>%
      filter(cali[,k] != 0) %>%
      summarise(avg_rating = mean(Rating))
    df <- rbind(df, avg_rating)
  } 
}
# shopping words, counts, and average ratings
shopping_mention_count <- data.frame(rides = names(colSums(cali[c(4:22)])), 
                                     counts = as.numeric(colSums(cali[c(4:22)])),
                                     avg_raing = df)
shopping_mention_count
```
Get frequency of each shopping word in total branch reviews & in reviews that mentioned shopping in the branch
```{r, warning=FALSE}
freq_all <- shopping_mention_count %>%
  mutate(freq_branch_pct = counts/nrow(cali)*100, 
         freq_Mention_pct = counts/counts[17]*100) %>%
  mutate_at(c(3:5), round, digits = 2)%>%
  arrange(desc(freq_Mention_pct)) 
freq_all
```

##### Rating Analysis
```{r, warning=FALSE}
p_mention_orno <- freq_all[c(1,3), 1:4]
p_mention_orno%>%
  ggplot(aes(x="", y=freq_branch_pct, fill=rides)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  labs(fill = "Shopping Words Mentioned") +
  ggtitle("Reviews that mentioned & did not mention shopping words in California Branch") +
  theme_void()+
  geom_text(aes(label = paste0(freq_branch_pct, "%")), position = position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#00A632", "#D6F1DF"), 
                    labels=c("Mentioned", "Did not mention"))
```

Proportions of shopping words mentioned in the branch over total number of reviews in the branch & over reviews that mentioned rides in branch
```{r, warning=FALSE, fig.width=12, fig.height=6}
p_shops <- freq_all[4:19, 1:5]

# filter freqs >= 2% of the reviews that mentioned rides in the branch, rating high to low
hot_shops <- p_shops %>%
  filter(freq_Mention_pct >= 2) 

shopping_rank_plot <- hot_shops%>%
  ggplot(aes(x=reorder(rides,freq_Mention_pct), 
             y=freq_Mention_pct, fill=freq_Mention_pct))+
  geom_col(position='dodge')+
  coord_flip()+
  labs(x = "", y = "Frequency in %") +
  ggtitle("All shopping words mentioned in California with % distribution")+
  scale_fill_gradient(low ="#D6F1DF", high = "#00A632", guide = FALSE) +
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.x  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.title = element_text(size = 20), 
        axis.text.x = element_text(size = 15), 
        axis.text.y = element_text(size = 13))

rating_rank_plot <- hot_shops %>%
  ggplot() +
  geom_col(aes(x=reorder(rides, -avg_rating), y=freq_Mention_pct, fill=freq_Mention_pct), 
           width=0.7, position='dodge')+  
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(-3, 25)) +
  geom_text(aes(x=rides, y=-1.2, label=avg_rating), size = 5) +
  labs(x = "Mostly mentioned shopping words", y = "Frequency in %") +
  ggtitle("Average rating ranked with most popular shopping words & no shopping words") +
  scale_fill_gradient(low ="#D6F1DF", high = "#00A632", guide = FALSE)+
  labs(tag ="Ratings:")+  
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.y  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.tag.position = c(0.005,0.135),
        plot.tag = element_text(hjust = 0, size=14),
        plot.title = element_text(size = 20), 
        axis.text.x = element_text(size = 15), 
        axis.text.y = element_text(size = 13))

#grid.arrange(shopping_rank_plot, rating_rank_plot, ncol = 2)
shopping_rank_plot
rating_rank_plot

```

From the two graph above, we can observe that "shop", "book", "bag" and "souvenir" are mentioned most frequently. Art, hat, gift and band receive higher ratings on average, but more frequently mentioned products and words received relatively lower rating. 



#### Paris
Cleaning texts:
```{r, message=FALSE, warning=FALSE}
corpus <- corpus_paris
corpus = tm_map(corpus,FUN = content_transformer(tolower))
corpus = tm_map(corpus,FUN = removePunctuation)
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))
corpus = tm_map(corpus,FUN = stripWhitespace)
#dict = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(disneyland$Review_Text))),
#                     lowfreq = 0)
#dict_corpus = Corpus(VectorSource(dict))
corpus = tm_map(corpus,FUN = stemDocument)
dtm_hk <- DocumentTermMatrix(corpus)
words_remove <- setdiff(colnames(dtm_hk), shopping_words)
length(words_remove)

corpus = tm_map(corpus, FUN = removeWords, words_remove[1:4000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[4001:7000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[7001:10000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[10001:13000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[13001:16000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[16001:19000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[19001:21000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[21001:24000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[24001:27000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[27001:30000])
corpus = tm_map(corpus, FUN = removeWords, words_remove[30001:32589])
corpus = tm_map(corpus, FUN = removeNumbers)
```


Transform cleaned corpus to document term matrix
```{r, message=FALSE, warning=FALSE}
dtm_paris_then <- DocumentTermMatrix(corpus)
colnames(dtm_paris_then)
```

Make data frame
```{r, message=FALSE, warning=FALSE}
dtm_paris_then = as.data.frame(as.matrix(dtm_paris_then))
sort(colSums(dtm_paris_then),decreasing = T)
```
Add information summarizing columns:
```{r, message=FALSE, warning=FALSE}
# add a column counting the number of shopping related words in a review
dtm_paris_then['shopping_word_count'] = rowSums(dtm_paris_then)
# add a column specifying if a review contains shopping related words
dtm_paris_then['if_shopping_word'] = ifelse(dtm_paris_then$shopping_word_count >= 1, 1, 0)
```

Attach word frequency to original data frame and select columns
```{r, message=FALSE, warning=FALSE}
paris <- paris %>%
  cbind(dtm_paris_then) %>%
  select(-Review_ID, -Reviewer_Location, 
         -Review_Text, -Year_Month, 
         -Year, -Month, -continent)
paris['no_shopping_word'] = ifelse(rowSums(paris[4:19]) == 0, 1, 0)
paris <- paris %>%
  select_if(function(x) !all(x == 0))
```

Calculate average ratings for each shopping words and add counts
```{r, message=FALSE, warning=FALSE}
shopping_paris = data.frame(rd=names(colSums(paris[c(4:22)])))
# average rating for each shopping word
df <- data.frame()
for (i in 1:nrow(shopping_paris)) { 
  for (k in shopping_paris[i,]) { 
    avg_rating <- paris %>%
      filter(paris[,k] != 0) %>%
      summarise(avg_rating = mean(Rating))
    df <- rbind(df, avg_rating)
  } 
}
# shopping words, counts, and average ratings
shopping_mention_count <- data.frame(rides = names(colSums(paris[c(4:22)])), 
                                     counts = as.numeric(colSums(paris[c(4:22)])),
                                     avg_raing = df)
shopping_mention_count
```

Get frequency of each shopping word in total branch reviews & in reviews that mentioned shopping in the branch
```{r, message=FALSE, warning=FALSE}
freq_all <- shopping_mention_count %>%
  mutate(freq_branch_pct = counts/nrow(paris)*100, 
         freq_Mention_pct = counts/counts[17]*100) %>%
  mutate_at(c(3:5), round, digits = 2)%>%
  arrange(desc(freq_Mention_pct)) 
freq_all
```

##### Rating Analysis
```{r, warning=FALSE, fig.width=12, fig.height=6}
p_mention_orno <- freq_all[c(1,3), 1:4]
p_mention_orno%>%
  ggplot(aes(x="", y=freq_branch_pct, fill=rides)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  labs(fill = "Shopping Words Mentioned") +
  ggtitle("Reviews that mentioned & did not mention shopping words in Paris Branch") +
  theme_void()+
  geom_text(aes(label = paste0(freq_branch_pct, "%")), position = position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#4169E2", "#D4DFFF"), 
                    labels=c("Mentioned", "Did not mention"))
```

Proportions of shopping words mentioned in the branch over total number of reviews in the branch & over reviews that mentioned rides in branch
```{r, warning=FALSE, fig.width=12, fig.height=6}
p_shops <- freq_all[4:19, 1:5]

# filter freqs >= 2% of the reviews that mentioned rides in the branch, rating high to low
hot_shops <- p_shops %>%
  filter(freq_Mention_pct >= 2) 

shopping_rank_plot <- hot_shops%>%
  ggplot(aes(x=reorder(rides,freq_Mention_pct), 
             y=freq_Mention_pct, fill=freq_Mention_pct))+
  geom_col(position='dodge')+
  coord_flip()+
  labs(x = "", y = "Frequency in %") +
  ggtitle("All shopping words mentioned in Paris with % distribution")+
  scale_fill_gradient(low ="#D4DFFF", high = "#4169E2", guide = FALSE) +
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(0, 40)) +
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.x  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.title = element_text(size = 20), 
        axis.text.x = element_text(size = 15), 
        axis.text.y = element_text(size = 15))

rating_rank_plot <- hot_shops %>%
  ggplot() +
  geom_col(aes(x=reorder(rides, -avg_rating), y=freq_Mention_pct, fill=freq_Mention_pct), 
           width=0.7, position='dodge')+  
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(-4.5, 40)) +
  geom_text(aes(x=rides, y=-2.5, label=avg_rating), size = 5) +
  labs(x = "Mostly mentioned shopping words", y = "Frequency in %") +
  ggtitle("Average rating ranked with most popular shopping words & no shopping words") +
  scale_fill_gradient(low ="#D4DFFF", high = "#4169E2", guide = FALSE)+
  labs(tag ="Ratings:")+  
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.y  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.tag.position = c(0.01,0.125),
        plot.tag = element_text(hjust = 0, size=15),
        plot.title = element_text(size = 20), 
        axis.text.x = element_text(size = 15), 
        axis.text.y = element_text(size = 13))

# grid.arrange(shopping_rank_plot, rating_rank_plot, ncol = 2)
shopping_rank_plot
rating_rank_plot
```

From the visualizations, "book" and "shop" are the leading words mentioned in the reviews, with "bag" and "toy" followed. Generally these shopping-related words received lower rating in Paris branch compared to the other two with souvenir and gift most favored by reviewers. 

#### Sentiment Analysis

##### Hong Kong
```{r, warning=FALSE}
afinn = read.csv(file = "afinn.csv", stringsAsFactors = F)
```
Integrate the three branches and attach to original dataset
```{r warning=FALSE}
# rbind all 3 branches 
tri_branch <- rbind(hongkong, cali, paris)
# cbind indicators to original dataset
disneyland <- cbind(disneyland, tri_branch[, 21])
colnames(disneyland)[11] <- 'if_shopping_words'
```

Distribution of sentiment scores with shopping words
```{r, message=FALSE, warning=FALSE}
dis_w_shop <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Hongkong Branch (with shopping words)")
dis_w_shop

```


Distribution of sentiment scores without shopping words
```{r message=FALSE, warning=FALSE}
dis_wt_shop <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Hongkong Branch (without shopping words)")
dis_wt_shop

```


##### California

Distribution of sentiment scores with shopping words
```{r message=FALSE, warning=FALSE}
dis_w_shop <- disneyland %>%
  filter(Branch == 'Disneyland_California', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in California Branch (with shopping words)")
dis_w_shop
```


Distribution of sentiment scores without shopping words
```{r message=FALSE, warning=FALSE}
dis_wt_shop <- disneyland %>%
  filter(Branch == 'Disneyland_California', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in California Branch (without shopping words)")
dis_wt_shop
```


##### Paris
Distribution of sentiment scores with shopping words
```{r message=FALSE, warning=FALSE}
dis_w_shop <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Paris Branch (with shopping words)")
dis_w_shop

```

Distribution of sentiment scores without shopping words
```{r message=FALSE, warning=FALSE}
dis_wt_shop <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)%>%
  summarize(reviewSentiment = mean(value))%>%
  ungroup()%>%
  ggplot(aes(x=reviewSentiment,fill=reviewSentiment>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Paris Branch (without shopping words)")
dis_wt_shop

```


#### Overall Sentiment Analytis
Calculate proportions and average scores required
```{r message=FALSE, warning=FALSE}
##### hong kong#####
# proportion of positive sentiment with shopping words
pos_prop_w_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / n())

#  proportion of positive sentiment without shopping words
pos_prop_wt_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / n())

# average sentiment score with shopping words
mean_w_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))

# average sentiment score without shopping words
mean_wt_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))


##### california #####
# proportion of positive sentiment with shopping words
pos_prop_w_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / n())

#  proportion of positive sentiment without shopping words
pos_prop_wt_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / n())

# average sentiment score with shopping words
mean_w_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))

# average sentiment score without shopping words
mean_wt_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))



##### paris #####
# proportion of positive sentiment with shopping words
pos_prop_w_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / n())

#  proportion of positive sentiment without shopping words
pos_prop_wt_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / n())

# average sentiment score with shopping words
mean_w_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', if_shopping_words == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))

# average sentiment score without shopping words
mean_wt_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', if_shopping_words == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))
```

Proportion of positive words in reviews w/wt shopping words
```{r message=FALSE, warning=FALSE}
# make proportion plot
df_prop = data.frame(branch = c('Hong Kong', 'California', 'Paris'),
                     prop_pos_words_w_shop = c(as.numeric(pos_prop_w_shop_hk), as.numeric(pos_prop_w_shop_ca), as.numeric(pos_prop_w_shop_paris)),
                     prop_pos_words_wt_shop = c(as.numeric(pos_prop_wt_shop_hk), as.numeric(pos_prop_wt_shop_ca), as.numeric(pos_prop_wt_shop_paris)))
df_prop_long <- tidyr::pivot_longer(df_prop, cols = c("prop_pos_words_w_shop", "prop_pos_words_wt_shop"), names_to = "category", values_to = "proportion")
ggplot(df_prop_long, aes(x = branch, y = proportion, fill = category)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "black", size = 0.5) +
  scale_fill_manual(values = c("#0072B2", "#F0E442"), 
                    labels=c("Mentioned", "Did not mention")) +
  labs(title = "Proportion of Positive Words with and without Shopping words", x = "Branch", y = "Proportion", fill = 'Shopping words mentioned') +
  geom_text(aes(label=round(proportion, 2)), position=position_dodge(width=0.9), vjust=-0.25) +
theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title = element_text(size = 14, face = "bold"),
        legend.title = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 12))
```

Average sentiment scores of reviews w/wt shopping words
```{r message=FALSE, warning=FALSE}
# make average score plot
df_mean = data.frame(branch = c('Hong Kong', 'California', 'Paris'),
                     mean_w_shop = c(as.numeric(mean_w_shop_hk), as.numeric(mean_w_shop_ca), as.numeric(mean_w_shop_paris)),
                     mean_wt_shop = c(as.numeric(mean_wt_shop_hk), as.numeric(mean_wt_shop_ca), as.numeric(mean_wt_shop_paris)))
df_mean_long <- tidyr::pivot_longer(df_mean, cols = c("mean_w_shop", "mean_wt_shop"), names_to = "category", values_to = "proportion")
ggplot(df_mean_long, aes(x = branch, y = proportion, fill = category)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "black", size = 0.5) +
  scale_fill_manual(values = c("#0072B2", "#F0E442"), 
                    labels=c("Mentioned", "Did not mention")) +
  labs(title = "Average sentiment scores with and without Shopping words", x = "Branch", y = "Average sentiment score", fill = 'Shopping words mentioned') +
  geom_text(aes(label=round(proportion, 2)), position=position_dodge(width=0.9), vjust=-0.25) +
theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title = element_text(size = 14, face = "bold"),
        legend.title = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 12))
```

From the proportion and average sentiment score graphs presented above, we observe that among all 3 branches, more positive words are in reviews unrelated to shopping experience, and reviews unrelated to shopping experience tend to have more positive tone than reviews that talked about shopping. We can thus conclude that it might be a common problem that Disneyland as a whole has to do better in improving travelers' shopping experience.

### Hypothesis 3:  

Ho: California Disneyland receives reviews related to rides experiences in similar proportion as other branches.  
Ha: California Disneyland receives reviews related to rides experiences in different proportion as other branches. 

```{r, echo=F, message = F, results = "hide", warning=FALSE}
disneyland<- read.csv(file = "disneyland.csv", stringsAsFactors = F)
rides <- read_csv('rides.csv')
```

##### Get ride names  

```{r, warning=FALSE}
rides_name <- rides$Ride_name
head(rides_name)
```

We matched ride features with reviews mentioned the ride, which is explained in detail in research question no.3.

```{r, warning=FALSE}
#rides_name[1:14]
disneyland_ride <- disneyland %>%
  mutate(Astro_Orbiter = case_when(grepl(c("astro orbiter", "Astro", "Orbiter"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Avatar_Flight = case_when(grepl(c("Avatar Flight of Passage", "Avatar Flight", "Avatar Ride"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Big_Thunder = case_when(grepl(c("Big Thunder Mountain Railroad", "Big Thunder"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Buzz_Lightyear = case_when(grepl(c("Buzz Lightyear's Space Ranger Spin", "Buzz Lightyear's", "Space Ranger Spin", "Space Ranger"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Dinosaur = case_when(grepl(c("Dinosaur"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Dumbo = case_when(grepl(c("Dumbo the Flying Elephant", "Flying Elephant"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Expedition_Everest = case_when(grepl(c("Expedition Everest"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Frozen_Ever = case_when(grepl(c("Frozen Ever After", "Ever After"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Gran_Fiesta = case_when(grepl(c("Gran Fiesta Tour Starring The Three Caballeros", "Gran Fiesta", "Starring The Three Caballeros", "Three Caballeros"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Haunted_Mansion = case_when(grepl(c("Haunted Mansion"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Small_World= case_when(grepl(c("It's a Small World", "Small World"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Journey_Into= case_when(grepl(c("Journey Into Imagination with Figment", "Imagination with Figment"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Jungle_Cruise= case_when(grepl(c("Jungle Cruise"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Kali_River = case_when(grepl(c("Kali River Rapids", "Kali River"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
```
```{r, warning=FALSE, echo=FALSE}
#rides_name[15:28]
disneyland_ride <- disneyland_ride %>%
  mutate(Kilimanjaro_Safaris = case_when(grepl(c("Kilimanjaro Safaris", "Kilimanjaro"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Living_With = case_when(grepl(c("Living with the Land"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Mad_Tea = case_when(grepl(c("Mad Tea Party", "Mad Tea"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Mission_Space = case_when(grepl(c("Mission Space"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Navi_River = case_when(grepl(c("Na'vi River Journey", "Na'vi"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Peter_Pan = case_when(grepl(c("Peter Pan's Flight", "Peter Pan's"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Pirates = case_when(grepl(c("Pirates of the Caribbean", "Pirates", "Caribbean"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Primeval_Whirl = case_when(grepl(c("Primeval Whirl"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Prince_Charming = case_when(grepl(c("Prince Charming Regal Carrousel", "Regal Carrousel"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Rock_Roller = case_when(grepl(c("Rock 'n' Roller Coaster", "Rock n"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Seven_Dwarfs = case_when(grepl(c("Seven Dwarfs Mine Train", "Mine Train"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Soarin_Around = case_when(grepl(c("Soarin' Around the World", "Soaring Around", "Soarin' Around"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Space_Mountain = case_when(grepl(c("Space Mountain"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Spaceship_Earthn = case_when(grepl(c("Spaceship Earth"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
```
```{r, warning=FALSE,echo=F}
#rides_name[29:42]
disneyland_ride <- disneyland_ride %>%
  mutate(Splash_Mountain = case_when(grepl(c("Splash Mountain"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Star_Tours = case_when(grepl(c("Star Tours"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Test_Track = case_when(grepl(c("Test Track"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Barnstormer = case_when(grepl(c("The Barnstormer"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Magic_Carpets = case_when(grepl(c("The Magic Carpets of Aladdin", "Magic Carpets"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Winnie_Pooh = case_when(grepl(c("The Many Adventures of Winnie the Pooh", "Many Adventures of Winnie"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Twilight_Zone = case_when(grepl(c("The Twilight Zone Tower of Terror", "Twilight Zone", "Tower of Terror"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Tomorrowland_Speedway = case_when(grepl(c("Tomorrowland Speedway"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Tomorrowland_Transit = case_when(grepl(c("Tomorrowland Transit Authority PeopleMover", "Transit Authority"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Toy_Story = case_when(grepl(c("Toy Story Mania"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(TriceraTop_Spin = case_when(grepl(c("TriceraTop Spin", "Tricera Top"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Under_Sea = case_when(grepl(c("Under the Sea"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(World_Railroad = case_when(grepl(c("Walt Disney World Railroad", "Disney World Railroad"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>% 
  mutate(Carousel_Progress = case_when(grepl(c("Walt Disney's Carousel of Progress", "Carousel of Progress"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
```

Because some of the rides only exists in the Orlando Disney, so we want to exclude the column associated with rides not being mentioned in any of the `Review_Text`.
```{r, warning=FALSE}
# rides mentioned in the Disneyland dataset: 27-3 = 24 rides. There are 40043 reviews. dropped other columns
disneyland_ride2 <- disneyland_ride %>% 
  select_if(function(x) !all(x == 0)) %>% 
  select(c(2,6,9,11:34))

# disneyland_ride2: 3 basic info + 24 rides + 2 mention columns. 29 cols, 40043 reviews
disneyland_ride2$mention_ride <-  ifelse(rowSums(disneyland_ride2[c(4:27)]) == 0, 0, 1)
disneyland_ride2$no_mention_ride <-  ifelse(rowSums(disneyland_ride2[c(4:27)]) == 0, 1, 0)
head(disneyland_ride2)
```             


Split dataset based on branch for those mentioned at least one ride
```{r, warning=FALSE}
# also remove ride columns that are not in branch
hongkong <- disneyland_ride2 %>%
  filter(Branch == 'Disneyland_HongKong') %>% 
  select_if(function(x) !all(x == 0))     # HK: 1:3(info) + 4:19(16 rides) + 20:21(mention cols)
cali <- disneyland_ride2 %>%
  filter(Branch == 'Disneyland_California') %>% 
  select_if(function(x) !all(x == 0))     # CA: 1:3(info) + 4:23(20 rides) + 24:25(mention cols)
paris <- disneyland_ride2 %>%
  filter(Branch == 'Disneyland_Paris') %>% 
  select_if(function(x) !all(x == 0))     # PR: 1:3(info) + 4:20(17 rides) + 21:22(mention cols)
```               
We structured the columns to be: 3 columns of basic information, ride dummy variables, and 2 columns indicating whether the line of the review mentioned rides or not.  
`hongkong`: 3 info + 16 rides + 2 mention columns for Hong Kong  
`cali`:     3 info + 20 rides + 2 mention columns for California  
`paris`:    3 info + 17 rides + 2 mention columns for Paris  


##### Hong Kong                

```{r}
head(hongkong)
rides_hk = data.frame(rd=names(colSums(hongkong[c(4:21)])))
rides_hk       # HK: 4:19(16 rides) + 20:21(2 mention cols)

colSums(hongkong[c(4:21)])

# get the avg rating for each ride
df <- data.frame()
for (i in 1:nrow(rides_hk)) { 
  for (k in rides_hk[i,]) { 
    avg_rating <- hongkong %>%
        filter(hongkong[,k] != 0) %>%
        summarise(avg_rating = mean(Rating))
    df <- rbind(df, avg_rating)
  } 
}

# ride names, counts, and average ratings
ride_mention_count <- data.frame(rides = names(colSums(hongkong[c(4:21)])), 
                                 counts = as.numeric(colSums(hongkong[c(4:21)])),
                                 avg_raing = df)

# Frequency of each ride in total branch reviews & in reviews that mentioned rides in the branch
freq_all <- ride_mention_count %>%
  mutate(freq_branch_pct = counts/nrow(hongkong)*100, 
         freq_Mention_pct = counts/counts[17]*100) %>%
  mutate_at(c(3:5), round, digits = 2)%>%
  arrange(desc(freq_Mention_pct)) 
freq_all
```




```{r}
# proportions of reviews that mentioned rides & no mention rides in the branch
p_mention_orno <- freq_all[1:2, 1:4]
p_mention_orno    

p_mention_orno%>%
  ggplot(aes(x="", y=freq_branch_pct, fill=rides)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  labs(fill = "Ride Experience Mentioned") +
  ggtitle("Reviews that mentioned & did not mention ride experiences in Hong Kong") +
  theme_void()+
  geom_text(aes(label = paste0(freq_branch_pct, "%")), position = position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#F1786C", "#E8CCC7"), 
                    labels=c("Mentioned", "Did not mention"))
```               
      
      
88.98% did not mention ride experiences in HK branch with an average rating of 4.21; 11.02% mentioned ride experiences in HK branch with a slightly higher average rating of 4.26.  


```{r, warning=FALSE, fig.width=12, fig.height=6}
# proportions of rides mentioned in the branch
# over total number of reviews in the branch & over reviews that mentioned rides in branch
p_rides <- freq_all[3:18, 1:5]

# filter freqs >= 2% of the reviews that mentioned rides in the branch, rating high to low
hot_rides <- p_rides %>%
  filter(freq_Mention_pct >= 2) 
hot_rides



# 
ride_rank_plot <- hot_rides%>%
  ggplot(aes(x=reorder(rides,freq_Mention_pct), 
             y=freq_Mention_pct, fill=freq_Mention_pct))+
  geom_col(position='dodge')+
  coord_flip()+
  labs(x = "", y = "Frequency in %") +
  ggtitle("All rides mentioned in Hong Kong with % distribution")+
  scale_fill_gradient(low = "#FCDADA", high = "#C50F0F", guide = FALSE) +
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.x  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.title = element_text(size = 15, hjust = -0.267, vjust = 1)) 

# rating  
rating_rank_plot <- hot_rides %>%
  ggplot() +
  geom_col(aes(x=reorder(rides, -avg_rating), y=freq_Mention_pct, fill=freq_Mention_pct), 
           width=0.7, position='dodge')+  
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(-10, 80)) +
  geom_text(aes(x=rides, y=-5, label=avg_rating), size = 4.5) +
  labs(x = "Mostly mentioned rides", y = "Frequency in %") +
  ggtitle("Average rating ranked with popular rides & no ride") +
  scale_fill_gradient(low = "#FCDADA", high = "#C50F0F", guide = FALSE)+
  labs(tag ="Ratings:")+  
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.y  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.tag.position = c(0.01,0.115),
        plot.tag = element_text(hjust = 0, size=12.5),
        plot.title = element_text(size = 15)) + 
  geom_vline(xintercept = 5.5, linetype = "dashed") +
  geom_text(aes(label = "No rides mentioned", x = 5.5, y=50), angle = 45, color = "#7C7C7C", size = 4)+
  geom_text(aes(label = "4.21", x = 5.5, y=-5), size = 4)



grid.arrange(ride_rank_plot, rating_rank_plot, ncol = 2)
```               
From the plot above, We can see that the mostly mentioned ride in Hong Kong branch is Space_Mountain ride, following by Small_World and Haunted_Mansion. Reviews who mentioned Small_World, Haunted_Mansion, and Star_Tours tend to give higher ratings on average. Space_Mountain, the ride that significantly more people mentioned about, obtained an average ratings that is only slightly higher than those that did not mention any rides. Pirates ride received lower rating than those did not mention rides, which might suggest that visitors might have bad impressions on this ride and caused them to leave a relatively neutral or negative ratings.  





##### California              

```{r}
head(cali)
rides_ca = data.frame(rd=names(colSums(cali[c(4:25)])))
rides_ca   # CA: 1:3(info) + 4:23(20 rides) + 24:25(2 mention cols)

colSums(cali[c(4:25)])

# get the avg rating for each ride
df <- data.frame()
for (i in 1:nrow(rides_ca)) { 
  for (k in rides_ca[i,]) { 
    avg_rating <- cali %>%
        filter(cali[,k] != 0) %>%
        summarise(avg_rating = mean(Rating))
    df <- rbind(df, avg_rating)
  } 
}

# ride names, counts, and average ratings
ride_mention_count <- data.frame(rides = names(colSums(cali[c(4:25)])), 
                                 counts = as.numeric(colSums(cali[c(4:25)])),
                                 avg_raing = df)

# Frequency of each ride in total branch reviews & in reviews that mentioned rides in the branch
freq_all <- ride_mention_count %>%
  mutate(freq_branch_pct = counts/nrow(cali)*100, 
         freq_Mention_pct = counts/counts[21]*100) %>%
  mutate_at(c(3:5), round, digits = 2)%>%
  arrange(desc(freq_Mention_pct)) 
freq_all
```

```{r}
# proportions of reviews that mentioned rides & no mention rides in the branch
p_mention_orno <- freq_all[1:2, 1:4]
p_mention_orno    

p_mention_orno%>%
  ggplot(aes(x="", y=freq_branch_pct, fill=rides)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  labs(fill = "Ride Experience Mentioned") +
  ggtitle("Reviews that mentioned & did not mention ride experiences in California") +
  theme_void()+
  geom_text(aes(label = paste0(freq_branch_pct, "%")), position = position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#19B34C", "#D6F1DF"), 
                    labels=c("Mentioned", "Did not mention"))
```               
      
      
83.08% did not mention ride experiences in CA branch with an average rating of 4.43; 16.92% mentioned ride experiences in CA branch with a slightly lower average rating of 4.36. This finding is different from What we had in HK branch, where the average rating is slightly higher for reviews that mentioned raide experiences.   



```{r, warning=FALSE, fig.width=12, fig.height=6}
# proportions of rides mentioned in the branch
# over total number of reviews in the branch & over reviews that mentioned rides in branch
p_rides <- freq_all[3:22, 1:5]

# filter freqs >= 2% of the reviews that mentioned rides in the branch, rating high to low
hot_rides <- p_rides %>%
  filter(freq_Mention_pct >= 2) 
hot_rides



#  
ride_rank_plot <- hot_rides%>%
  ggplot(aes(x=reorder(rides,freq_Mention_pct), 
             y=freq_Mention_pct, fill=freq_Mention_pct))+
  geom_col(position='dodge')+
  coord_flip()+
  labs(x = "", y = "Frequency in %") +
  ggtitle("All rides mentioned in California with % distribution")+
  scale_fill_gradient(low = "#D6F1DF", high = "#19B34C", guide = FALSE) +
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.x  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.title = element_text(size = 15, hjust = -0.267, vjust = 1)) 

# 
rating_rank_plot <- hot_rides %>%
  ggplot() +
  geom_col(aes(x=reorder(rides, -avg_rating), y=freq_Mention_pct, fill=freq_Mention_pct), 
           width=0.7, position='dodge')+  
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(-10, 80)) +
  geom_text(aes(x=rides, y=-5, label=avg_rating), size = 4.5) +
  labs(x = "Mostly mentioned rides", y = "Frequency in %") +
  ggtitle("Average rating ranked with popular rides & no ride") +
  scale_fill_gradient(low = "#D6F1DF", high = "#19B34C", guide = FALSE)+
  labs(tag ="Ratings:")+  
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.y  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.tag.position = c(0.01,0.108),
        plot.tag = element_text(hjust = 0, size=12.5),
        plot.title = element_text(size = 15)) + 
  geom_vline(xintercept = 3, linetype = "dashed") +
  geom_text(aes(label = "No rides mentioned", x = 3, y=50), angle = 45, color = "#7C7C7C", size = 4)+
  geom_text(aes(label = " ", x = 5.5, y=-5), size = 5)



grid.arrange(ride_rank_plot, rating_rank_plot, ncol = 2)
```               
From the plot above, We can see that the mostly mentioned ride in California branch is also Space_Mountain ride, which is the same as in Hong Kong branch, following by Splash_Mountain and Haunted_Mansion. However, when it comes to average ratings, we found that in California, rides that people tend to mention more about did not lead to higher ratings. The rating even tend to be lower than those did not mention any rides. The mostly mentioned ride, Space_Mountain, received an average rating of 4.37. Although this average rating is slightly higher than the same ride in Hong Kong branch, it is even lower than the ratings that did not mention rides in California. This might suggest that consumers are not entirely happy about their general ride experiences.  


##### Paris                

```{r}
head(paris)
rides_pr = data.frame(rd=names(colSums(paris[c(4:22)])))
rides_pr    # PR: 4:20(17 rides) + 21:22(2 mention cols)

colSums(paris[c(4:22)])

# get the avg rating for each ride
df <- data.frame()
for (i in 1:nrow(rides_pr)) { 
  for (k in rides_pr[i,]) { 
    avg_rating <- paris %>%
        filter(paris[,k] != 0) %>%
        summarise(avg_rating = mean(Rating))
    df <- rbind(df, avg_rating)
  } 
}

# ride names, counts, and average ratings
ride_mention_count <- data.frame(rides = names(colSums(paris[c(4:22)])), 
                                 counts = as.numeric(colSums(paris[c(4:22)])),
                                 avg_raing = df)

# Frequency of each ride in total branch reviews & in reviews that mentioned rides in the branch
freq_all <- ride_mention_count %>%
  mutate(freq_branch_pct = counts/nrow(paris)*100, 
         freq_Mention_pct = counts/counts[18]*100) %>%
  mutate_at(c(3:5), round, digits = 2)%>%
  arrange(desc(freq_Mention_pct)) 
freq_all
```

```{r}
# proportions of reviews that mentioned rides & no mention rides in the branch
p_mention_orno <- freq_all[1:2, 1:4]
p_mention_orno
#                 avg_rating  frequency %
# HK: no_mention:   4.21        88.98
#     mentioned:    4.26        11.02
# CA: no_mention:   4.43        83.08   
#     mentioned:    4.36        16.92


p_mention_orno%>%
  ggplot(aes(x="", y=freq_branch_pct, fill=rides)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  labs(fill = "Ride Experience Mentioned") +
  ggtitle("Reviews that mentioned & did not mention ride experiences in Paris") +
  theme_void()+
  geom_text(aes(label = paste0(freq_branch_pct, "%")), position = position_stack(vjust=0.5)) +
  scale_fill_manual(values=c("#4169E2", "#BACBFF"), 
                    labels=c("Mentioned", "Did not mention"))
```               
      
      
84.63% did not mention ride experiences in PR branch with an average rating of 3.98; 15.37% mentioned ride experiences in PR branch with a very similar average rating of 3.97. Comparing to the two branches before, the two average ratings are much lower than in HK and CA. This might suggest that Paris branch receive generally lower ratings compared to other branches. The proportions of rides mentioned in the review text verses did not are  similar compared to other two branches. 


```{r, warning=FALSE, fig.width=12, fig.height=6}
# proportions of rides mentioned in the branch
# over total number of reviews in the branch & over reviews that mentioned rides in branch
p_rides <- freq_all[3:19, 1:5]

# filter freqs >= 2% of the reviews that mentioned rides in the branch, rating high to low
hot_rides <- p_rides %>%
  filter(freq_Mention_pct >= 2) 
hot_rides


ride_rank_plot <- hot_rides%>%
  ggplot(aes(x=reorder(rides,freq_Mention_pct), 
             y=freq_Mention_pct, fill=freq_Mention_pct))+
  geom_col(position='dodge')+
  coord_flip()+
  labs(x = "", y = "Frequency in %") +
  ggtitle("All rides mentioned in Paris with % distribution")+
  scale_fill_gradient(low = "#D4DFFF", high = "#083DDC", guide = FALSE) +
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.x  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.title = element_text(size = 15, hjust = -0.267, vjust = 1)) 


rating_rank_plot <- hot_rides %>%
  ggplot() +
  geom_col(aes(x=reorder(rides, -avg_rating), y=freq_Mention_pct, fill=freq_Mention_pct), 
           width=0.7, position='dodge')+  
  scale_y_continuous(name = "Frequency in %", 
                     expand = c(0,0),
                     limits = c(-10, 80)) +
  geom_text(aes(x=rides, y=-5, label=avg_rating), size = 4.5) +
  labs(x = "Mostly mentioned rides", y = "Frequency in %") +
  ggtitle("Average rating ranked with popular rides & no ride") +
  scale_fill_gradient(low = "#D4DFFF", high = "#083DDC", guide = FALSE)+
  labs(tag ="Ratings:")+  
  theme(plot.background = element_blank(), 
        panel.background = element_blank(), 
        panel.grid.major.y  = element_line(color = "light grey"),
        axis.line = element_line(color = "black"),
        plot.tag.position = c(0.01,0.115),
        plot.tag = element_text(hjust = 0, size=12.5),
        plot.title = element_text(size = 15)) + 
  geom_vline(xintercept = 3.5, linetype = "dashed") +
  geom_text(aes(label = "No rides mentioned", x = 3.5, y=70), angle = 30, color = "#7C7C7C", size = 4)+
  geom_text(aes(label = "3.98", x = 3.5, y=-5), size = 4)

grid.arrange(ride_rank_plot, rating_rank_plot, ncol = 2)
```               
The mostly mentioned ride in Paris branch is also Space_Mountain ride, following by Pirates and Star_Tours. As mentioned before, the general rating for Paris branch is much lower than other two branches. This is also true for the reviews regardless of mentioning or not mentioning ride experiences. Peter_Pan and Small_World received similarly higher average ratings, following by Space_Mountain. Reviewers who did not mention any ride rated slightly higher on average than other rides including Pirates, Star_Tours, and Haunted Mansion. This might suggest that apart from Peter_Pan and Small_World, rides that are most frequently mentioned in Paris branch might tend to receive more neutral ratings. People tend not to give higher ratings when they mention rides that are popular or mostly mentioned compared with the ratings without mentioning rides, in which case, these most mentioned rides tend not to be more favorable among visitors.  
 




#### Sentiment Analysis  


##### Hong Kong
```{r}
afinn = read.csv(file = "afinn.csv", stringsAsFactors = F)
```

Integrate the three branches and attach to original dataset
```{r}
# rbind all 3 branches 
tri_branch <- rbind(hongkong[,20:21], cali[,24:25], paris[,21:22])
# cbind indicators to original dataset
disneyland <- cbind(disneyland, tri_branch)
```

Distribution of sentiment scores with ride experience
```{r message=FALSE, warning=FALSE}
dis_w_shop <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', mention_ride == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)

agg_data <- aggregate(dis_w_shop[, 'value'], by = list(dis_w_shop$Review_ID), FUN = function(x) mean(x))

colnames(agg_data) <- c("Review_ID", "mean_value")
agg_data %>%
  ggplot(aes(x=mean_value,fill=mean_value>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Hongkong Branch (contain ride experience)")


```

Distribution of sentiment scores without ride experience
```{r message=FALSE, warning=FALSE}
dis_wt_shop <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', mention_ride == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)
agg_data <- aggregate(dis_wt_shop[, 'value'], by = list(dis_wt_shop$Review_ID), FUN = function(x) mean(x))

colnames(agg_data) <- c("Review_ID", "mean_value")
agg_data %>%
  ggplot(aes(x=mean_value,fill=mean_value>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Hongkong Branch (not contain ride experience)")

```

##### California
Distribution of sentiment scores with ride experience
```{r message=FALSE, warning=FALSE}
dis_w_shop <- disneyland %>%
  filter(Branch == 'Disneyland_California', mention_ride == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)

agg_data <- aggregate(dis_w_shop[, 'value'], by = list(dis_w_shop$Review_ID), FUN = function(x) mean(x))

colnames(agg_data) <- c("Review_ID", "mean_value")
agg_data %>%
  ggplot(aes(x=mean_value,fill=mean_value>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in California Branch (contain ride experience)")


```

Distribution of sentiment scores without ride experience
```{r message=FALSE, warning=FALSE}
dis_wt_shop <- disneyland %>%
  filter(Branch == 'Disneyland_California', mention_ride == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)
agg_data <- aggregate(dis_wt_shop[, 'value'], by = list(dis_wt_shop$Review_ID), FUN = function(x) mean(x))

colnames(agg_data) <- c("Review_ID", "mean_value")
agg_data %>%
  ggplot(aes(x=mean_value,fill=mean_value>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in California Branch (not contain ride experience)")

```

##### Paris
Distribution of sentiment scores with ride experience
```{r message=FALSE, warning=FALSE}
dis_w_shop <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', mention_ride == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)

agg_data <- aggregate(dis_w_shop[, 'value'], by = list(dis_w_shop$Review_ID), FUN = function(x) mean(x))

colnames(agg_data) <- c("Review_ID", "mean_value")
agg_data %>%
  ggplot(aes(x=mean_value,fill=mean_value>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Paris Branch (contain ride experience)")


```

Distribution of sentiment scores without ride experience
```{r message=FALSE, warning=FALSE}
dis_wt_shop <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', mention_ride == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn)
agg_data <- aggregate(dis_wt_shop[, 'value'], by = list(dis_wt_shop$Review_ID), FUN = function(x) mean(x))

colnames(agg_data) <- c("Review_ID", "mean_value")
agg_data %>%
  ggplot(aes(x=mean_value,fill=mean_value>0))+
  geom_histogram(binwidth = 0.1)+
  scale_x_continuous(breaks=seq(-5,5,1))+
  scale_fill_manual(values=c('tomato','seagreen'))+
  theme_bw() +
  labs(x = "Review Sentiment Scores", y = "Number of Reviews") +
  ggtitle("Distribution of Review Sentiment in Paris Branch (not contain ride experience)")

```

##### Overall Sentiment Analytis
Calculate proportions and average scores required
```{r message=FALSE, warning=FALSE}
##### hong kong#####
# proportion of positive sentiment with shopping words
pos_prop_w_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', mention_ride == 1) %>%
  select(Review_ID, Review_Text) %>%
  unnest_tokens(output = word, input = Review_Text) %>%
  inner_join(afinn) %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / NROW(word))

#  proportion of positive sentiment without shopping words
pos_prop_wt_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', mention_ride == 0) %>%
  select(Review_ID, Review_Text) %>%
  unnest_tokens(output = word, input = Review_Text) %>%
  inner_join(afinn) %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / NROW(word))


# average sentiment score with shopping words
mean_w_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', mention_ride == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))

# average sentiment score without shopping words
mean_wt_shop_hk <- disneyland %>%
  filter(Branch == 'Disneyland_HongKong', mention_ride == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))


##### california #####
# proportion of positive sentiment with shopping words
pos_prop_w_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', mention_ride == 1) %>%
  select(Review_ID, Review_Text) %>%
  unnest_tokens(output = word, input = Review_Text) %>%
  inner_join(afinn) %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / NROW(word))

#  proportion of positive sentiment without shopping words
pos_prop_wt_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', mention_ride == 0) %>%
  select(Review_ID, Review_Text) %>%
  unnest_tokens(output = word, input = Review_Text) %>%
  inner_join(afinn) %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / NROW(word))

# average sentiment score with shopping words
mean_w_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', mention_ride == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))

# average sentiment score without shopping words
mean_wt_shop_ca <- disneyland %>%
  filter(Branch == 'Disneyland_California', mention_ride == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))



##### paris #####
# proportion of positive sentiment with shopping words
pos_prop_w_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', mention_ride == 1) %>%
  select(Review_ID, Review_Text) %>%
  unnest_tokens(output = word, input = Review_Text) %>%
  inner_join(afinn) %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / NROW(word))

#  proportion of positive sentiment without shopping words
pos_prop_wt_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', mention_ride == 0) %>%
  select(Review_ID, Review_Text) %>%
  unnest_tokens(output = word, input = Review_Text) %>%
  inner_join(afinn) %>%
  mutate(positive = ifelse(value >= 0, 1, 0)) %>%
  summarize(proportion_positive = sum(positive) / NROW(word))

# average sentiment score with shopping words
mean_w_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', mention_ride == 1) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))

# average sentiment score without shopping words
mean_wt_shop_paris <- disneyland %>%
  filter(Branch == 'Disneyland_Paris', mention_ride == 0) %>%
  select(Review_ID,Review_Text)%>%
  group_by(Review_ID)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  inner_join(afinn) %>%
  ungroup() %>%
  summarize(avg = mean(value))
```

Proportion of positive words in reviews w/wt shopping words
```{r message=FALSE, warning=FALSE}
# make proportion plot
df_prop = data.frame(branch = c('Hong Kong', 'California', 'Paris'),
                     prop_pos_words_w_shop = c(as.numeric(pos_prop_w_shop_hk), as.numeric(pos_prop_w_shop_ca), as.numeric(pos_prop_w_shop_paris)),
                     prop_pos_words_wt_shop = c(as.numeric(pos_prop_wt_shop_hk), as.numeric(pos_prop_wt_shop_ca), as.numeric(pos_prop_wt_shop_paris)))
df_prop_long <- tidyr::pivot_longer(df_prop, cols = c("prop_pos_words_w_shop", "prop_pos_words_wt_shop"), names_to = "category", values_to = "proportion")
ggplot(df_prop_long, aes(x = branch, y = proportion, fill = category)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "black", size = 0.5) +
  scale_fill_manual(values = c("#0072B2", "#F0E442"), 
                    labels=c("Mentioned", "Did not mention")) +
  labs(title = "Proportion of Positive Words with and without ride experience", x = "Branch", y = "Proportion", fill = 'Ride experience mentioned') +
  geom_text(aes(label=round(proportion, 2)), position=position_dodge(width=0.9), vjust=-0.25) +
theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title = element_text(size = 14, face = "bold"),
        legend.title = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 12))
```

Average sentiment scores of reviews w/wt shopping words
```{r message=FALSE, warning=FALSE}
# make average score plot
df_mean = data.frame(branch = c('Hong Kong', 'California', 'Paris'),
                     mean_w_shop = c(as.numeric(mean_w_shop_hk), as.numeric(mean_w_shop_ca), as.numeric(mean_w_shop_paris)),
                     mean_wt_shop = c(as.numeric(mean_wt_shop_hk), as.numeric(mean_wt_shop_ca), as.numeric(mean_wt_shop_paris)))
df_mean_long <- tidyr::pivot_longer(df_mean, cols = c("mean_w_shop", "mean_wt_shop"), names_to = "category", values_to = "proportion")
ggplot(df_mean_long, aes(x = branch, y = proportion, fill = category)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7, color = "black", size = 0.5) +
  scale_fill_manual(values = c("#0072B2", "#F0E442"), 
                    labels=c("Mentioned", "Did not mention")) +
  labs(title = "Average sentiment scores with and without ride experience", x = "Branch", y = "Average sentiment score", fill = 'Ride experience mentioned') +
  geom_text(aes(label=round(proportion, 2)), position=position_dodge(width=0.9), vjust=-0.25) +
theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title = element_text(size = 14, face = "bold"),
        legend.title = element_text(size = 12, face = "bold"),
        legend.text = element_text(size = 12))
```  


Regarding sentiment analysis, the difference in proportion of positive words between reviews with ride experience or not is ambiguous, but the average sentiment score for ride-related reviews are much lower, indicating that reviewers may have more extreme emotions toward ride experience. Thus, every branch should examine each of their ride services and make improvements accordingly. 


## Research Question No.3
We classified the topic words in the reviews into four categories: time, theme rides, dining, and customer services. We aim to find which specific topic words/word categories reviewers share in their reviews when they tend to provide a high & low rating.  

Hypothesis 1:  
Ho: Reviews discussing time words would not affect overall review ratings.  
Ha: Reviews discussing time words would affect overall review ratings.  
Hypothesis 2:  
Ho: Reviews discussing food words would not affect overall review ratings.  
Ha: Reviews discussing food words would affect overall review ratings.  
Hypothesis 3:  
Ho: Rides features would not affect overall review ratings.  
Ha: Rides features would affect overall review ratings. 
Hypothesis 4:  
Ho: Reviews discussing staff would not affect overall review ratings.  
Ha: Reviews discussing staff would affect overall review ratings.  

### Clean and Tokenize

We created a corpus of the reviews from the variable Review_Text using library(tm), and then preprocessed the corpus of reviews using functions from library(tm) as well. Specifically, we  transformed text to lower case, removed punctuation, removed English stopwords using the dictionary tm::stopwords("english"), removed numbers, remove whitespace, and stemed documents. We also retained all terms that appear in 5% or more reviews and converted the document-term-matrix to a data frame so that the column names would be the tokens.

```{r}
head(disneyland)
#install.packages("tm")
library(tm)
#install.packages('topicmodels')
library(topicmodels)

#Clean the Review_Text column:
corpus1 <- Corpus(VectorSource(disneyland$Review_Text))

#(a) transform text to lower case,
corpus1 = tm_map(corpus1,FUN = content_transformer(tolower))

#(b) remove punctuation,
corpus1 = tm_map(corpus1,FUN = removePunctuation)

#(c) remove English stopwords using the following dictionary tm::stopwords("english")
corpus1 = tm_map(corpus1,FUN = removeWords,c(stopwords('english')))

#(d) remove numbers
corpus1 = tm_map(corpus1,FUN = removeNumbers)

#(e) remove whitespace
corpus1 = tm_map(corpus1,FUN = stripWhitespace)

#(f) stem words
corpus1 = tm_map(corpus1,FUN = stemDocument)

dict1 = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(disneyland$Review_Text))),
                     lowfreq = 0)
dict_corpus1 = Corpus(VectorSource(dict1))


dtm1 <- DocumentTermMatrix(corpus1)

# Remove Sparse Terms 
xdtm1 = removeSparseTerms(dtm1,sparse = 0.95)
 #xdtm

# Complete Stems
xdtm1 = as.data.frame(as.matrix(xdtm1))
colnames(xdtm1) = stemCompletion(x = colnames(xdtm1),
                                dictionary = dict_corpus1,
                                type='prevalent')
colnames(xdtm1) = make.names(colnames(xdtm1))
head(sort(colSums(xdtm1),decreasing = T))

```

We also created another document term matrix using Term Frequency - Inverse Document Frequency Weighting.

```{r}
# Document Term Matrix - tfidf
dtm_tfidf1 = DocumentTermMatrix(x=corpus1,
                               control = list(weighting=function(x) weightTfIdf(x,normalize=F)))
xdtm_tfidf1 = removeSparseTerms(dtm_tfidf1,sparse = 0.95)
xdtm_tfidf1 = as.data.frame(as.matrix(xdtm_tfidf1))
colnames(xdtm_tfidf1) = stemCompletion(x = colnames(xdtm_tfidf1),
                                      dictionary = dict_corpus1,
                                      type='prevalent')
colnames(xdtm_tfidf1) = make.names(colnames(xdtm_tfidf1))
head(sort(colSums(xdtm_tfidf1),decreasing = T))
```

Then we plotted a bar chart which contrasts the weights of term frequency and term frequency inverse document frequency weighting for the top 35 terms.

```{r}
library(tidyr); library(dplyr); library(ggplot2); library(ggthemes)
data.frame(term = colnames(xdtm1),tf = colMeans(xdtm1), tfidf = colMeans(xdtm_tfidf1))%>%
  arrange(desc(tf))%>%
  top_n(35)%>%
  gather(key=weighting_method,value=weight,2:3)%>%
  ggplot(aes(x=term,y=weight,fill=weighting_method))+
  geom_col(position='dodge')+
  coord_flip()+
  theme_economist()+ 
  scale_fill_manual(values = brewer.pal(9, "Set2")[c(7, 8)])
 

```


After tokenizing the reviews' word frequency as a whole, we could see that reviewers mentioned factors, such as time, rides, and food, very frequently, no matter using Term Frequency - Inverse Document Frequency Weighting or not. Therefore, topic word categories can be considered as time, theme rides, dining, and customer services, and topic words are time, rides, staff, and food. These motivated us to further separate ratings and sentiments to inspect words in negative-rating reviews (ratings under 3).    

We created two document term matrices using both Term frequency and Term Frequency - Inverse Document Frequency Weighting for the negative-rating reviews and plotted a bar chart for the top 30 terms to compare two weightings. Similar to the bar chart of all-rating reviews above, Terms "ride" and "park" are heavy weighted. Term Frequency assigns them a heavy weight because they are the most frequently occurring term, and they appear in most of the reviews as well, while Term Frequency - Inverse Document Frequency assigns them a much lower weight.  Topic word "food" is in the collection as well. Nevertheless, term "show" is not included while "staff" appears. And terms related to time are included a lot, such as "wait," "minute," and "hour."

```{r}
negativeDisney<-disneyland %>% subset(Rating == c(1,2))
# Create a document-term matrix for the negative sentiment words

#Clean the Review_Text column:
corpus <- Corpus(VectorSource(negativeDisney$Review_Text))

#(a) transform text to lower case,
corpus = tm_map(corpus,FUN = content_transformer(tolower))

#(b) remove punctuation,
corpus = tm_map(corpus,FUN = removePunctuation)

#(c) remove English stopwords using the following dictionary tm::stopwords("english")
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))

#(d) remove numbers
corpus = tm_map(corpus,FUN = removeNumbers)

#(e) remove whitespace
corpus = tm_map(corpus,FUN = stripWhitespace)

#(f) stem words
corpus = tm_map(corpus,FUN = stemDocument)

dtm <- DocumentTermMatrix(corpus)
 #inspect(dtm)

dict = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(negativeDisney$Review_Text))),
                     lowfreq = 0)
dict_corpus = Corpus(VectorSource(dict))

# Remove Sparse Terms 
xdtm = removeSparseTerms(dtm,sparse = 0.95)
 #xdtm

# Complete Stems
xdtm = as.data.frame(as.matrix(xdtm))
colnames(xdtm) = stemCompletion(x = colnames(xdtm),
                                dictionary = dict_corpus,
                                type='prevalent')
colnames(xdtm) = make.names(colnames(xdtm))
head(sort(colSums(xdtm),decreasing = T))

# Document Term Matrix - tfidf
dtm_tfidf = DocumentTermMatrix(x=corpus,
                               control = list(weighting=function(x) weightTfIdf(x,normalize=F)))
xdtm_tfidf = removeSparseTerms(dtm_tfidf,sparse = 0.95)
xdtm_tfidf = as.data.frame(as.matrix(xdtm_tfidf))
colnames(xdtm_tfidf) = stemCompletion(x = colnames(xdtm_tfidf),
                                      dictionary = dict_corpus,
                                      type='prevalent')
colnames(xdtm_tfidf) = make.names(colnames(xdtm_tfidf))
head(sort(colSums(xdtm_tfidf),decreasing = T))

```


```{r}
data.frame(term = colnames(xdtm),tf = colMeans(xdtm), tfidf = colMeans(xdtm_tfidf))%>%
  arrange(desc(tf))%>%
  top_n(30)%>%
  gather(key=weighting_method,value=weight,2:3)%>%
  ggplot(aes(x=term,y=weight,fill=weighting_method))+
  geom_col(position='dodge')+
  coord_flip()+
  theme_economist()+ 
  scale_fill_manual(values = brewer.pal(9, "Set2")[c(7, 8)])
```


After zooming into the negative-rating reviews, we would like to take a look at the neutral-rating and positive rating reviews as well. For neutral-rating reviews (rating=3), we plotted the bar chart again to contrast the weights of term frequency and term frequency inverse document frequency weighting for the top 30 terms. Terms "ride" and "park" are heavy weighted again. Time words and food remain as two of the focuses. Term "staff" is still in the top 30, but the term "show" appears this time.


```{r}
neutralDisney<-disneyland %>% subset(Rating == 3)
# Create a document-term matrix for the negative sentiment words

#Clean the Review_Text column:
corpus <- Corpus(VectorSource(neutralDisney$Review_Text))

#(a) transform text to lower case,
corpus = tm_map(corpus,FUN = content_transformer(tolower))

#(b) remove punctuation,
corpus = tm_map(corpus,FUN = removePunctuation)

#(c) remove English stopwords using the following dictionary tm::stopwords("english")
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))

#(d) remove numbers
corpus = tm_map(corpus,FUN = removeNumbers)

#(e) remove whitespace
corpus = tm_map(corpus,FUN = stripWhitespace)

#(f) stem words
corpus = tm_map(corpus,FUN = stemDocument)

dtm <- DocumentTermMatrix(corpus)
 #inspect(dtm)

dict = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(neutralDisney$Review_Text))),
                     lowfreq = 0)
dict_corpus = Corpus(VectorSource(dict))

# Remove Sparse Terms 
xdtm = removeSparseTerms(dtm,sparse = 0.95)
 #xdtm

# Complete Stems
xdtm = as.data.frame(as.matrix(xdtm))
colnames(xdtm) = stemCompletion(x = colnames(xdtm),
                                dictionary = dict_corpus,
                                type='prevalent')
colnames(xdtm) = make.names(colnames(xdtm))
head(sort(colSums(xdtm),decreasing = T))

# Document Term Matrix - tfidf
dtm_tfidf = DocumentTermMatrix(x=corpus,
                               control = list(weighting=function(x) weightTfIdf(x,normalize=F)))
xdtm_tfidf = removeSparseTerms(dtm_tfidf,sparse = 0.95)
xdtm_tfidf = as.data.frame(as.matrix(xdtm_tfidf))
colnames(xdtm_tfidf) = stemCompletion(x = colnames(xdtm_tfidf),
                                      dictionary = dict_corpus,
                                      type='prevalent')
colnames(xdtm_tfidf) = make.names(colnames(xdtm_tfidf))
head(sort(colSums(xdtm_tfidf),decreasing = T))

data.frame(term = colnames(xdtm),tf = colMeans(xdtm), tfidf = colMeans(xdtm_tfidf))%>%
  arrange(desc(tf))%>%
  top_n(30)%>%
  gather(key=weighting_method,value=weight,2:3)%>%
  ggplot(aes(x=term,y=weight,fill=weighting_method))+
  geom_col(position='dodge')+
  coord_flip()+
  theme_economist()+ 
  scale_fill_manual(values = brewer.pal(9, "Set2")[c(7, 8)])
```


We also plotted term frequency versus term frequency inverse document frequency weighting top-30-term bar chart for the positive-rating reviews as shown below. We could see that terms like "love" and "enjoy" appear in the top 30, while time words 


```{r}
positiveDisney<-disneyland %>% subset(Rating == c(4,5))
# Create a document-term matrix for the negative sentiment words

#Clean the Review_Text column:
corpus <- Corpus(VectorSource(positiveDisney$Review_Text))

#(a) transform text to lower case,
corpus = tm_map(corpus,FUN = content_transformer(tolower))

#(b) remove punctuation,
corpus = tm_map(corpus,FUN = removePunctuation)

#(c) remove English stopwords using the following dictionary tm::stopwords("english")
corpus = tm_map(corpus,FUN = removeWords,c(stopwords('english')))

#(d) remove numbers
corpus = tm_map(corpus,FUN = removeNumbers)

#(e) remove whitespace
corpus = tm_map(corpus,FUN = stripWhitespace)

#(f) stem words
corpus = tm_map(corpus,FUN = stemDocument)

dtm <- DocumentTermMatrix(corpus)
 #inspect(dtm)

dict = findFreqTerms(DocumentTermMatrix(Corpus(VectorSource(positiveDisney$Review_Text))),
                     lowfreq = 0)
dict_corpus = Corpus(VectorSource(dict))

# Remove Sparse Terms 
xdtm = removeSparseTerms(dtm,sparse = 0.95)
 #xdtm

# Complete Stems
xdtm = as.data.frame(as.matrix(xdtm))
colnames(xdtm) = stemCompletion(x = colnames(xdtm),
                                dictionary = dict_corpus,
                                type='prevalent')
colnames(xdtm) = make.names(colnames(xdtm))
head(sort(colSums(xdtm),decreasing = T))

# Document Term Matrix - tfidf
dtm_tfidf = DocumentTermMatrix(x=corpus,
                               control = list(weighting=function(x) weightTfIdf(x,normalize=F)))
xdtm_tfidf = removeSparseTerms(dtm_tfidf,sparse = 0.95)
xdtm_tfidf = as.data.frame(as.matrix(xdtm_tfidf))
colnames(xdtm_tfidf) = stemCompletion(x = colnames(xdtm_tfidf),
                                      dictionary = dict_corpus,
                                      type='prevalent')
colnames(xdtm_tfidf) = make.names(colnames(xdtm_tfidf))
head(sort(colSums(xdtm_tfidf),decreasing = T))

data.frame(term = colnames(xdtm),tf = colMeans(xdtm), tfidf = colMeans(xdtm_tfidf))%>%
  arrange(desc(tf))%>%
  top_n(30)%>%
  gather(key=weighting_method,value=weight,2:3)%>%
  ggplot(aes(x=term,y=weight,fill=weighting_method))+
  geom_col(position='dodge')+
  coord_flip()+
  theme_economist()+ 
  scale_fill_manual(values = brewer.pal(9, "Set2")[c(7, 8)])
```

After plotting three term frequency versus term frequency inverse document frequency weighting top-30-term bar charts, we found that term "staff" only appears in top 30 of negative and neutral rating reviews. Term "food," topic words related to "time," and term "ride" are shown in all three types of rating reviews. Therefore, we would like to further investigate these terms separately. 


#### Term "Food"

Based on previous analysis, term "food" is a focus over all rating reviews.

```{r}
# create a vector of food-related keywords
keywords <- c('food','foods', 'eating','eat','ate', 'restaurant', 'meal','drink','snack','churro','cake','turkey','corn','popcorn','pretzel','pizza','taco', 'burger','sandwiche','milkshake','fries', 'chicken','beef','pork', 'beer','wine','breakfast','lunch','dinner')

# create a logical vector indicating whether each Review_Text contains at least one keyword
contains_keyword <- grepl(paste0("\\b", keywords, "\\b", collapse = "|"), disneyland$Review_Text, ignore.case = TRUE)

# subset the original dataframe to create a new dataframe allFoods containing only rows with Review_text that contains at least one keyword
allFoods <- disneyland[contains_keyword, ]
str(allFoods)
```


We found out the total number of positive and negative words in the reviews and plotted bar charts.

```{r}
allFoods%>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Review_Text)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()

# bar chart for positive and negative sentiments in reviews mentioned foods over 5 ratings using 'bing' dictionary
allFoods %>%
  select(Review_ID,Review_Text,Rating)%>%
  group_by(Review_ID, Rating)%>%
  unnest_tokens(output=word,input=Review_Text)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(Rating,sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))%>%
  ggplot(aes(x=Rating,y=proportion,fill=sentiment))+
  geom_col()+
  theme_economist()+
  coord_flip()

# bar chart for Rating Distribution for Reviews Mentioned Foods
ggplot(allFoods, aes(Rating))+
  geom_bar(stat = "count",position = 'dodge', fill="mistyrose3")+
  ggtitle("Rating Distribution for Reviews Mentioned Foods")
```


Considering that the reviews contains comments about other aspects, such as rides and shows, we further examine sentences mentioned foods by selecting foods-related sentences and stored in a new dataframe foodSentences_ratings, which contains combined food-related sentences (one reviewer may has two or more sentences), Review_ID, and Rating. 


```{r}
# Split the Review_Text column into sentences 
allFoods_sentences <- allFoods %>%
  unnest_tokens(output=sentence, input=Review_Text, "sentences")

# Filter the sentences containing at least one food word 
foodSentences <- allFoods_sentences %>%
  filter(grepl(paste(keywords, collapse="|"), sentence))

dim(foodSentences)
head(foodSentences)

# Combine the sentences for each unique Reviewer_ID
foodSentences_combined <- aggregate(sentence ~ Review_ID, data = foodSentences, FUN = paste, collapse = " ")
    #foodSentences_combined

# Join the foodSentences_combined and allFoods dataframes by Reviewer_ID
foodSentences_ratings <- left_join(foodSentences_combined, allFoods[, c("Review_ID", "Rating")], by = "Review_ID")

dim(foodSentences_ratings)
head(foodSentences_ratings)
```

We used "bing" dictionary and ‘nrc’ lexicon to examine the sentiments in the food sentences. 

```{r}
#plot a bar chart with "bing" dictionary
foodSentences_ratings%>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip()

# plot another bar chart based on ratings
foodSentences_ratings %>%
  select(Review_ID,sentence,Rating)%>%
  group_by(Review_ID, Rating)%>%
  unnest_tokens(output=word,input=sentence)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(Rating,sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))%>%
  ggplot(aes(x=Rating,y=proportion,fill=sentiment))+
  geom_col()+
  theme_economist()+
  coord_flip()

# plot a bar chart with ‘nrc’ lexicon 
library(lexicon)
nrc<-read.csv("nrc.csv")

foodSentences_ratings%>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj()
```


From the plots above, we can see that overall most reviewers maintain a positive attitude towards foods. The number of positive sentiment is about twice amount of number of negative sentiment. The number of positive emotions based on "nrc" lexicon is also relatively high. Therefore, we further zoomed into negative rating sentences to investigate the emotions expressed about foods in the low ratings (Rating == c(1,2)). 

```{r}
negativeFoods<-foodSentences_ratings %>% subset(Rating == c(1,2))
head(negativeFoods)

negativeFoods%>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  arrange(desc(n))

#plot a bar chart with "bing" dictionary
negativeFoods%>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip()

# plot a bar chart with ‘nrc’ lexicon 
negativeFoods%>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj()
```

The plots above show that in the negative ratings (Ratings under 3), most reviewers hold a negative attitude towards foods, which means that foods-related things may play a role in low ratings. Below we checked 20 reviews mentioned foods in low ratings.


```{r}
# we checked 20 reviews, but only show 6 here.
head(negativeFoods$sentence, 3)
tail(negativeFoods$sentence, 3)
```

There are many foods-related issues, including over-pricing, not enough and unclean eating places, offering too much unhealthy/poor quality food, and too long waiting time.


#### Time Words

Considering words related to time were mentioned frequently by reviewers giving negative reviews, we would like to investigate more about time words in the reviews. By using `spacyr` package that provides an interface to the spaCy natural language processing (NLP) library in Python, we were able to do Named Entity Recognition (NER). NER can be helpful for text classification tasks and identify and classify named entities in text. Through using function `spacy_parse`, we could access time words through the time entity, which is consisted of "TIME_I" and "TIME_B." The letters "B" and "I" at the end of each entity type indicate whether the entity is the beginning ("B"), such as "45," or inside ("I"), such as "minites," of a multi-word entity.


```{r}
library(spacyr)
library(reshape2)
#spacy_upgrade()

# Initialize connection to Python spaCy and create automatic Named Entity Recognition features.
spacy_initialize("en_core_web_sm")
#spacy_install("en_core_web_sm")
#spacy_initialize(model = "en_core_web_sm")

ner_negativeDisney <- spacy_parse(negativeDisney$Review_Text, tag = FALSE, 
                                entity = TRUE,lemma = FALSE) 

glimpse(ner_negativeDisney)


wide_ner_negativeDisney <- dcast(ner_negativeDisney, doc_id ~ entity, value.var="entity")
glimpse(wide_ner_negativeDisney)

# Extract time words. 
time_entities <- subset(ner_negativeDisney, entity == c("TIME_I", "TIME_B")) %>%
  group_by(token) %>% summarize(count = n())%>%
  ungroup()%>%
  arrange(desc(count))%>%top_n(15)
time_entities


# Plot a barchart for time words
#install.packages("pals")
library("pals")
ggplot(time_entities, aes(x=reorder(token,-count), y=count)) +
  geom_bar(stat = "identity", aes(fill = as.factor(token))) +
  labs(title = "Time Words in Negative Disneyland Reviews", 
       x = "Time words", y = "Count") +
  theme_economist()+ 
  scale_fill_manual(values=as.vector(brewer.set2(20)))
```

The time plot above shows that hours and minutes are mentioned frequently in negative reviews, so we speculate that many visitors' waiting time are quite long. However, these are the unit words, we need to construct predictive models to see how time issues related to low ratings.

#### Rides Mentioned in Review
```{r}
#Testing how to extract reviews mentioning specific rides name
library(dplyr)
library(stringr)
rides_name <- rides$Ride_name
rides_name[1]
disneyland_1 <- disneyland %>%
  mutate(Astro_Orbiter = case_when(grepl(c("astro orbiter", "Astro", "Orbiter"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
ao <- disneyland_1 %>%
  filter(Astro_Orbiter == 1)
ao

rides_name[2]
disneyland_2 <- disneyland %>%
  mutate(Avatar_Flight = case_when(grepl(c("Avatar Flight of Passage", "Avatar Flight", "Avatar Ride"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
af <- disneyland_2 %>%
  filter(Avatar_Flight == 1)
af

rides_name[3]
disneyland_3 <- disneyland %>%
  mutate(Big_Thunder = case_when(grepl(c("Big Thunder Mountain Railroad", "Big Thunder"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
bt <- disneyland_3 %>%
  filter(Big_Thunder == 1)
bt

rides_name
```
We want to detect if some review mentioned specific rides name. For example, if some review mentioned "Astro Orbiter" in `Review_Text`, we create a new column called `Astro_Orbiter`. If mentioned, we enter 1 under the `Astro_Orbiter` column, otherwise we enter 0.   
We want to do the same for all 42 rides in the "rides" dataset, and hence we could match ride features with reviews mentioned the ride. 
```{r}
library(dplyr)
library(stringr)

rides_name[1:14]
disneyland_ride <- disneyland %>%
  mutate(Astro_Orbiter = case_when(grepl(c("astro orbiter", "Astro", "Orbiter"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Avatar_Flight = case_when(grepl(c("Avatar Flight of Passage", "Avatar Flight", "Avatar Ride"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Big_Thunder = case_when(grepl(c("Big Thunder Mountain Railroad", "Big Thunder"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Buzz_Lightyear = case_when(grepl(c("Buzz Lightyear's Space Ranger Spin", "Buzz Lightyear's", "Space Ranger Spin", "Space Ranger"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Dinosaur = case_when(grepl(c("Dinosaur"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Dumbo = case_when(grepl(c("Dumbo the Flying Elephant", "Flying Elephant"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Expedition_Everest = case_when(grepl(c("Expedition Everest"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Frozen_Ever = case_when(grepl(c("Frozen Ever After", "Ever After"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Gran_Fiesta = case_when(grepl(c("Gran Fiesta Tour Starring The Three Caballeros", "Gran Fiesta", "Starring The Three Caballeros", "Three Caballeros"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Haunted_Mansion = case_when(grepl(c("Haunted Mansion"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Small_World= case_when(grepl(c("It's a Small World", "Small World"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Journey_Into= case_when(grepl(c("Journey Into Imagination with Figment", "Imagination with Figment"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Jungle_Cruise= case_when(grepl(c("Jungle Cruise"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Kali_River = case_when(grepl(c("Kali River Rapids", "Kali River"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))

head(disneyland_ride)
```
```{r}
rides_name[15:28]
disneyland_ride <- disneyland_ride %>%
  mutate(Kilimanjaro_Safaris = case_when(grepl(c("Kilimanjaro Safaris", "Kilimanjaro"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Living_With = case_when(grepl(c("Living with the Land"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Mad_Tea = case_when(grepl(c("Mad Tea Party", "Mad Tea"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Mission_Space = case_when(grepl(c("Mission Space"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Navi_River = case_when(grepl(c("Na'vi River Journey", "Na'vi"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Peter_Pan = case_when(grepl(c("Peter Pan's Flight", "Peter Pan's"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Pirates = case_when(grepl(c("Pirates of the Caribbean", "Pirates", "Caribbean"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Primeval_Whirl = case_when(grepl(c("Primeval Whirl"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Prince_Charming = case_when(grepl(c("Prince Charming Regal Carrousel", "Regal Carrousel"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Rock_Roller = case_when(grepl(c("Rock 'n' Roller Coaster", "Rock n"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Seven_Dwarfs = case_when(grepl(c("Seven Dwarfs Mine Train", "Mine Train"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Soarin_Around = case_when(grepl(c("Soarin' Around the World", "Soaring Around", "Soarin' Around"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Space_Mountain = case_when(grepl(c("Space Mountain"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Spaceship_Earthn = case_when(grepl(c("Spaceship Earth"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
```

```{r}
rides_name[29:42]
disneyland_ride <- disneyland_ride %>%
  mutate(Splash_Mountain = case_when(grepl(c("Splash Mountain"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Star_Tours = case_when(grepl(c("Star Tours"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Test_Track = case_when(grepl(c("Test Track"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Barnstormer = case_when(grepl(c("The Barnstormer"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Magic_Carpets = case_when(grepl(c("The Magic Carpets of Aladdin", "Magic Carpets"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Winnie_Pooh = case_when(grepl(c("The Many Adventures of Winnie the Pooh", "Many Adventures of Winnie"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Twilight_Zone = case_when(grepl(c("The Twilight Zone Tower of Terror", "Twilight Zone", "Tower of Terror"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Tomorrowland_Speedway = case_when(grepl(c("Tomorrowland Speedway"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Tomorrowland_Transit = case_when(grepl(c("Tomorrowland Transit Authority PeopleMover", "Transit Authority"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Toy_Story = case_when(grepl(c("Toy Story Mania"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(TriceraTop_Spin = case_when(grepl(c("TriceraTop Spin", "Tricera Top"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(Under_Sea = case_when(grepl(c("Under the Sea"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>%
  mutate(World_Railroad = case_when(grepl(c("Walt Disney World Railroad", "Disney World Railroad"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0)) %>% 
  mutate(Carousel_Progress = case_when(grepl(c("Walt Disney's Carousel of Progress", "Carousel of Progress"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
```
We manually matched ride names and `Review_Text` because we want to include possible variation of rides name mentioned in review. For example, there is a ride called "Seven Dwarfs Mine Train", so we detected both "Seven Dwarfs Mine Train" (the official ride name) and possible abbreviated ride name "Main Train" (also with insensitive letter case). However, we cannot grantee we have included all occurrence. Because if there is a typo in visitors' review, or another way to call the ride, we would not be able to match them.   
There are also ride name including a Disney character, for example "Peter Pan's Flight". We include "Peter Pan's" as abbreviated ride name. But we cannot be sure if reviews using such words is mentioning the ride or the character in Disneyland who is interacting with visitors.   
Maybe in future NLP analysis, we can figure out whether "Peter Pan" is referring to the Disney character or the ride name when we can successfully capture the context of the review. We hope to find solutions in future analysis, but for now, we would use the manually matched dataset.  

Because some of the rides only exists in the Orlando Disney, so we want to exclude the column associated with rides not being mentioned in any of the `Review_Text`.
```{r}
#only keep the row if at least one of the ride name column is 1
disneyland_ride2 <- disneyland_ride %>% 
  select_if(function(x) !all(x == 0)) 
head(disneyland_ride2)

# Plot the number of times each ride being mentioned in reviews:
rides_sum <- disneyland_ride2 %>% 
  select(11:34) %>% 
  colSums()
rides_sum

rides_sum <- rides_sum[order(-rides_sum)]
barplot(rides_sum, main = "Number of Times Each Ride Being Mentioned", xlab = "Ride Names", ylab = "Count", col = "lightblue", density = 30, las = 2, cex.names = 0.6, ylim = c(0, 3500))
```
From the above plot, we know that "Space Mountain", "Pirates", "Hunted Mansion", "Star Tours", and "Splash Mountain" are the five rides being mentioned the most times. 


##### Analyze Ride called Space Mountain (mentioned the most in Review): 
Given so many rides, we want to analyze "Space Mountain" as it is the ride being mentioned the most in reviews. 
```{r}
rides_sum

#filter out reviews mentioned Space Mountain
spaceMountain <- disneyland_ride2 %>%
  filter(Space_Mountain == 1) 
head(spaceMountain)

library(ggplot2)
plot1 <- ggplot(spaceMountain, aes(Rating)) +
         geom_bar(stat="count", position = "dodge") +
  ggtitle('Rating Distribution for Reviews Mentioned Ride Space Mountain')
plot1

#filter out negative reviews mentioned Space Mountain
spaceMountain_Neg <- spaceMountain %>%
  filter(Rating_type == "negative") 

plot2 <- ggplot(spaceMountain_Neg, aes(Rating)) +
         geom_bar(stat="count", position = "dodge") +
  ggtitle('Rating Distribution for Negtaive Reviews Mentioned Ride Space Mountain')
plot2

#for all Space Mountain(pos and neg) reviews, detect the specific sentence containing Space Mountain regardless of letter case
spaceMountain <- spaceMountain %>%
  mutate(Ride_Sentence = str_extract(Review_Text, "(?i)\\b[^.]*Space Mountain[^.]*\\b"))
spaceMountain
```
From the "Rating Distribution for Reviews Mentioned Ride Space Mountain", we can see that there are more 5 score ratings mentioning "Space Mountain" than lower score ratings. Overall, visitors experience with Space Mountain is positive.   
We extracted the specific sentence in `Review_Text` mentioning Space Mountain Ride, and store the sentence in the `Ride_Sentence` column. 

We hope to use a Binary Sentiment Lexicons called "bing" to categorize words in `Ride_Sentence` as being positive or negative.
```{r}
library(tidytext)
as.data.frame(get_sentiments('bing'))[1:50,]
get_sentiments('bing')%>%
  group_by(sentiment)%>%
  count()

spaceMountain %>%
  group_by(Review_ID) %>%
  unnest_tokens(output = word, input = Ride_Sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip() +
  labs(title = "Sentiment Analysis of All Reviews for Space Mountain") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
#observe more positive words than negative words overall

#see if this is true in negative reviews:
spaceMountain_Neg <- spaceMountain %>%
  filter(Rating_type == "negative")

spaceMountain_Neg %>%
  group_by(Review_ID) %>%
  unnest_tokens(output = word, input = Ride_Sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip() +
  labs(title = "Sentiment Analysis of Negative Reviews for Space Mountain") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
#even if in overall negatively rated reviews, we still has more positive words in the sentence mentioned 'Space Mountain'. 

#see comparison bewteen review rating and sentiment
library(ggthemes)
spaceMountain %>%
  select(Review_ID, Ride_Sentence, Rating)%>%
  group_by(Review_ID, Rating)%>%
  unnest_tokens(output=word,input= Ride_Sentence)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(Rating,sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))%>%
  ggplot(aes(x= Rating,y=proportion,fill=sentiment))+
  geom_col()+
  theme_economist()+
  coord_flip() +
  labs(title = "Sentiment Analysis of Reviews for Space Mountain in Different Rating Categories") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
```
From the "Sentiment Analysis of All Reviews for Space Mountain" plot, we see more positive sentiment than negative sentiment in all kinds of reviews. From the "Sentiment Analysis of Negative Reviews for Space Mountain", we also observe more positive sentiment than negative sentiment when filter out only negative reviews (rated 1 or 2). But we can see the difference is smaller. And from the "Sentiment Analysis of Reviews for Space Mountain in Different Rating Categories" plot, we observe a similar pattern as before. There are both positive and negative sentiments in each rating categories. Positive reviews (4 and 5) has more positive sentiment proportion, and negative reviews (1 and 2) has more negative sentiment proportion. 

Now, we want to observe the emotions in reviews mentioned ride Space Mountain. 
```{r}
nrc = read.table(file = 'https://raw.githubusercontent.com/pseudorational/data/master/nrc_lexicon.txt',
                 header = F,
                 col.names = c('word','sentiment','num'),
                 sep = '\t',
                 stringsAsFactors = F)
nrc = nrc[nrc$num!=0,]
nrc$num = NULL
```

```{r}
spaceMountain %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Ride_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  arrange(desc(n))

spaceMountain %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Ride_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj() +
  labs(title = "NRC Analysis of ALL Reviews Mentioned Space Mountain") +
  theme(plot.title = element_text(size = 10, color = "darkgreen"))

spaceMountain_Neg %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Ride_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj() +
  labs(title = "NRC Analysis of Negative Reviews Mentioned Space Mountain") +
  theme(plot.title = element_text(size = 10, color = "darkgreen"))
```
From "NRC Analysis of ALL Reviews Mentioned Space Mountain" plot, "anticipation" and "positive" emotion appear more frequently than "negative" or "fear". In the "NRC Analysis of Negative Reviews Mentioned Space Mountain", we still observe many "anticipation" and "positive" feelings, but "fear" and "sadness" moved up the ranking. Meaning that, the overall emotions people towards the ride Space Mountain is still more positive even if they rated 1 or 2 for the general Disneyland experience. The use of negative words to express emotion and feeling is more frequent in negative rated reviews.

##### Analyze Ride called Pirates (second mostly mentioned): 
We want to analyze Pirates of the Caribbean Ride as well, since it is the ride with the second most number of occurrence in reviews. If we have more time in the future, we would analyze each ride one by one. But for now we only picked the first two because they have large sample sizes and the results is less biased. 
```{r}
rides_sum

#filter out reviews mentioned Space Mountain
pirates <- disneyland_ride2 %>%
  filter(Pirates == 1) 
head(pirates)

library(ggplot2)
plot3 <- ggplot(pirates, aes(Rating)) +
         geom_bar(stat="count", position = "dodge") +
  ggtitle('Rating Distribution for Reviews Mentioned Ride pirates')
plot3

#filter out negative reviews mentioned pirates
pirates_Neg <- pirates %>%
  filter(Rating_type == "negative") 

plot4 <- ggplot(pirates_Neg, aes(Rating)) +
         geom_bar(stat="count", position = "dodge") +
  ggtitle('Rating Distribution for Negtaive Reviews Mentioned Ride Pirates')
plot4

#for all Pirates (pos and neg) reviews, detect the specific sentence containing Pirates regardless of letter case
pirates <- pirates %>%
  mutate(Pirates_Sentence = str_extract(Review_Text, "(?i)\\b[^.]*pirates[^.]*\\b"))
pirates
```
From the "Rating Distribution for Reviews Mentioned Ride pirates" we again observe a similar rating pattern for all Disney reviews (regardless of mentioning ride or not) and the space mountain ride. The five-score rated review are the most, the one-score rated review are the least. 

```{r}
pirates %>%
  group_by(Review_ID) %>%
  unnest_tokens(output = word, input = Pirates_Sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip() +
  labs(title = "Sentiment Analysis of All Reviews for Pirates") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
#observe more positive words than negative words overall

#see if this is true in negative reviews:
pirates_Neg <- pirates %>%
  filter(Rating_type == "negative")

pirates_Neg %>%
  group_by(Review_ID) %>%
  unnest_tokens(output = word, input = Pirates_Sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip() +
  labs(title = "Sentiment Analysis of Negative Reviews for Pirates") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
#even if in overall negatively rated reviews, we still has more positive words in the sentence mentioned 'Space Mountain'. 

#see comparison bewteen review rating and sentiment
library(ggthemes)
pirates %>%
  select(Review_ID, Pirates_Sentence, Rating)%>%
  group_by(Review_ID, Rating)%>%
  unnest_tokens(output=word,input= Pirates_Sentence)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(Rating,sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))%>%
  ggplot(aes(x= Rating,y=proportion,fill=sentiment))+
  geom_col()+
  theme_economist()+
  coord_flip() +
  labs(title = "Sentiment Analysis of All Reviews for Pirates Across All Rating Categories") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
```
We observe more positive reviews for both "Sentiment Analysis of All Reviews for Pirates" plot and "Sentiment Analysis of Negative Reviews for Pirates". Meaning that the general experience with the Ride Pirates of the Caribbean is positive even if visitors gave a negative rating.   
From the "Sentiment Analysis of All Reviews for Pirates Across All Rating Categories" plot, we observe a different proportion pattern. For all review rating categories, there are more positive sentiment than negative sentiment. Five-score rated reviews still has the most positive sentiment proportion, but two-score rated reviews has more positive sentiment proportion than 3-score rated reviews.

```{r}
pirates %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Pirates_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  arrange(desc(n))

pirates %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Pirates_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj() +
  labs(title = "NRC Analysis of ALL Reviews Mentioned Pirates") +
  theme(plot.title = element_text(size = 10, color = "darkgreen"))

pirates_Neg %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Pirates_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj() +
  labs(title = "NRC Analysis of Negative Reviews Mentioned Pirates") +
  theme(plot.title = element_text(size = 10, color = "darkgreen"))
```
From the "NRC Analysis of ALL Reviews Mentioned Pirates" plots, we see that "positive" and "anticipation" are at the top of the ranking, follow by "negative". We observe a similar ranking at the "NRC Analysis of Negative Reviews Mentioned Pirates" plot. 

##### Adding Ride Features
We want to combine ride features in the "ride" dataset to our "disneyland_ride2" dataset so we can explore whether there is some relationship between ride features and rating.
We filter out reviews mentioned one and only one ride because if there is more than one rides mentioned, we cannot match the corresponding ride features and cannot explore the link towards rating. 
```{r}
head(disneyland_ride2,200)

#filter out reviews mentioned at least one ride
disneyland_ride3 <- disneyland_ride2 %>%
  filter(rowSums(disneyland_ride2[, 11:34]) != 0)

#filter out reviews mentioned exactly one ride
disneyland_ride4 <- disneyland_ride3[rowSums(disneyland_ride3[, 11:34] == 1) == 1, ]
head(disneyland_ride4)

#create new column get the name of the ride mentioned in review
disneyland_ride4 <- disneyland_ride4 %>%
  mutate(Ride_Mentioned = case_when(
    `Astro_Orbiter` == 1 ~ "Astro Orbiter",
    `Big_Thunder` == 1 ~ "Big Thunder Mountain Railroad",
    `Dinosaur` == 1 ~ "Dinosaur",
    `Dumbo` == 1 ~ "Dumbo the Flying Elephant",
    `Expedition_Everest` == 1 ~ "Expedition Everest",
    `Haunted_Mansion` == 1 ~ "Haunted Mansion",
    `Small_World` == 1 ~ "It's a Small World",
    `Jungle_Cruise` == 1 ~ "Jungle Cruise",
    `Mad_Tea` == 1 ~ "Mad Tea Party",
    `Mission_Space` == 1 ~ "Mission Space",
    `Peter_Pan` == 1 ~ "Peter Pan's Flight",
    `Pirates` == 1 ~ "Pirates of the Caribbean",
    `Rock_Roller` == 1 ~ "Rock 'n' Roller Coaster",
    `Seven_Dwarfs` == 1 ~ "Seven Dwarfs Mine Train",
    `Soarin_Around` == 1 ~ "Soarin' Around the World",
    `Space_Mountain` == 1 ~ "Space Mountain",
    `Splash_Mountain` == 1 ~ "Splash Mountain",
    `Star_Tours` == 1 ~ "Star Tours",
    `Test_Track` == 1 ~ "Test Track",
    `Winnie_Pooh` == 1 ~ "The Many Adventures of Winnie the Pooh",
    `Twilight_Zone` == 1 ~ "The Twilight Zone Tower of Terror",
    `Tomorrowland_Speedway` == 1 ~ "Tomorrowland Speedway",
    `Toy_Story` == 1 ~ "Toy Story Mania",
    `Under_Sea` == 1 ~ "Under the Sea",
    TRUE ~ NA_character_
  ))

#drop irrelevant columns:
disneyland_ride4 <- disneyland_ride4 %>% 
  select(-c(11:34))
head(disneyland_ride4,100)

#combine two dataset
head(rides)
rides_new <- rides[, -c(2, 3)]

disneyland_ridefull <- disneyland_ride4 %>% 
                    left_join(rides_new, by = c("Ride_Mentioned" = "Ride_name"))
disneyland_ridefull
```

##### Rides Features and Rating
```{r}
R_thrill <- disneyland_ridefull %>%
  filter(Ride_type_thrill == 1)

plot_thrill <- ggplot(R_thrill, aes(Rating)) +
         geom_bar(stat="count", position = "dodge")
plot_thrill 
ggplot(data = disneyland_ridefull, aes(Rating, fill = Ride_type_all)) +
  geom_bar(stat = "count", position = "stack") +
  labs(title = "Count of Ride Ratings by Ride Type Across All Rating Categories") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
```
From the above plot, we observe that for each rating categories, we have similar distribution for `ride_type_all`. Specifically, rides that are "thrill, big drops, dark" occupies the most in all rating types.    
We want to see ride features individually, so we would separate the features and see if there is some effect towards rating. 

```{r}
#Thrill
thrill_prop <- disneyland_ridefull %>% 
  group_by(Rating, Ride_type_thrill) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))

ggplot(thrill_prop, aes(x = Rating, y = prop, fill = factor(Ride_type_thrill))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink"), 
                    name = "If Ride is Thrill",
                    labels = c("Not Thrilling", "Thrilling")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on Rides' Thrillness") +
  theme_bw()
```
```{r}
head(disneyland_ridefull)
#Spinning
spin_prop <- disneyland_ridefull %>% 
  group_by(Rating, Ride_type_spinning) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
spin_prop

ggplot(spin_prop, aes(x = Rating, y = prop, fill = factor(Ride_type_spinning))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink"), 
                    name = "If Ride is Spinning",
                    labels = c("Not Spinning", "Spinning")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on Rides' Spinningness") +
  theme_bw()
```
```{r}
head(disneyland_ridefull)
#Slow
slow_prop <- disneyland_ridefull %>% 
  group_by(Rating, Ride_type_slow) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
slow_prop

ggplot(slow_prop, aes(x = Rating, y = prop, fill = factor(Ride_type_slow))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink"), 
                    name = "If Ride is Spinning",
                    labels = c("Quick", "Slow")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on Rides' Speed") +
  theme_bw()
```
```{r}
head(disneyland_ridefull)
#check if Small Drops and Big Drops complement each other
all(disneyland_ridefull$Ride_type_small_drops == !disneyland_ridefull$Ride_type_big_drops)
#They do not complement each other -> might be rides with no drops at all

disneyland_ridefull <- disneyland_ridefull %>%
  mutate(Ride_type_drop = if_else(Ride_type_small_drops == 1, 1,
                                  if_else(Ride_type_big_drops == 1, 2, 0)))

drop_prop <- disneyland_ridefull %>% 
  group_by(Rating, Ride_type_drop) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
drop_prop

ggplot(drop_prop, aes(x = Rating, y = prop, fill = factor(Ride_type_drop))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink", "mediumpurple"), 
                    name = "If Ride has Drops",
                    labels = c("No Drops", "Small Drops", "Big Drops")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on Rides' Drop Type") +
  theme_bw()
```
```{r}
head(disneyland_ridefull)
#Dark
dark_prop <- disneyland_ridefull %>% 
  group_by(Rating, Ride_type_dark) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
dark_prop

ggplot(dark_prop, aes(x = Rating, y = prop, fill = factor(Ride_type_dark))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink"), 
                    name = "If Ride is Dark",
                    labels = c("Not Dark", "Dark")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on Rides' Darkness") +
  theme_bw()
```
```{r}
head(disneyland_ridefull)
#scary
scary_prop <- disneyland_ridefull %>% 
  group_by(Rating, Ride_type_scary) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
scary_prop

ggplot(scary_prop, aes(x = Rating, y = prop, fill = factor(Ride_type_scary))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink"), 
                    name = "If Ride is Scary",
                    labels = c("Not Scary", "Scary")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on Rides' Scariness") +
  theme_bw()
```

```{r}
head(disneyland_ridefull)
#water
water_prop <- disneyland_ridefull %>% 
  group_by(Rating, Ride_type_water) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
water_prop

ggplot(water_prop, aes(x = Rating, y = prop, fill = factor(Ride_type_water))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink"), 
                    name = "If Ride has Water",
                    labels = c("No Water", "Water")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on if Rides has Water") +
  theme_bw()
```

```{r}
head(disneyland_ridefull)
#if can use fast pass
table(disneyland_ridefull$Fast_pass)
# Almost all ride can use fast pass, skip this feature
```

```{r}
table(disneyland_ridefull$Classic)

#classic
classic_prop <- disneyland_ridefull %>% 
  group_by(Rating, Classic) %>% 
  summarize(n = n()) %>% 
  mutate(prop = n/sum(n))
classic_prop

ggplot(classic_prop, aes(x = Rating, y = prop, fill = factor(Classic))) + 
  geom_col(position = "stack") +
  scale_fill_manual(values = c("lightblue", "pink"), 
                    name = "If Ride is Classic",
                    labels = c("No", "Yes")) +
  labs(x = "Rating", y = "Proportion", title = "Proportion of Ratings based on if Rides is Classic") +
  theme_bw()
```
From all of the above plots, we can see that no matter what ride feature it is, the distribution in each rating category's bar is the same. Meaning that the ride feature is not associate with ratings. Using the "Proportion of Ratings based on Rides' Speed" as an example, if see the distribution of Quick rides increases when rating increases, that could symbolize a quick ride would have higher rating than a slow ride. But what we got is the same distribution across all ratings, and this only symbolizes the proportion of quick and slow rides in Disneyland. 
The spinning graph tells that there are more non-spinning rides in the park so neutrally there will be more reviews mentioning rides with a non-spinning features across all rating categories.  

```{r}
ggplot(data = disneyland_ridefull, aes(Rating, fill = Age_interest_all)) +
  geom_bar(stat = "count", position = "stack") +
  labs(title = "Count of Ride Ratings by Ride Age Interest Group Across All Rating Categories") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
```
The "kids, teens, teens, adults" group only exclude the "preschoolers" from "all ages" group. All rating categories have similar age group distribution. 


```{r}
linear_model <- lm(Rating ~ Ride_type_thrill + Ride_type_slow + Ride_type_spinning + Ride_type_drop + Ride_type_dark + Ride_type_scary + Ride_type_water + Classic +  Height_req_inches + Ride_duration_min, data = disneyland_ridefull)
summary(linear_model)
plot(linear_model)
```

We built a multi-variable linear regression models to see if ride features has effect on overall disneyland rating. We only observe a small p-value for `Ride_type_drop`. We reject the null hypothesis and conclude that number of drops a ride has will have effect on Disneyland's overall rating. From the graph, we conclude that visitor experiencing rides with no drop will give a higher rating. We found that reviews mentioning rides with no drops tend to give higher ratings. For other ride features, we have large p-values so we fail to reject null hypothesis. Meaning that reviews mentioning ride features other than drops would not affect overall rating.

#### Term "Staff"
From the tf/tfidf graph, we see many reviews mentioning "staff". We would like to explore reviews and the specific sentence in the review mentioned about staff (as part of customer experience description). We hope to know the relationship between review mentioning staff and the overall disneyland experience rating.
```{r}
library(dplyr)
library(stringr)

#creating new column called staff, if review_text include "staff", store 1, otherwise 0
disneyland_staff <- disneyland %>%
  mutate(Staff = case_when(grepl(c("staff"), Review_Text, ignore.case = TRUE) ~ 1, 
                                   TRUE ~ 0))
#filter out rows that mentioned staff in review_text
staff <- disneyland_staff %>%
  filter(Staff == 1)
head(staff)
#find the exact sentence in Review_Text column that mentioned about staff
staff <- staff %>%
  mutate(Staff_Sentence = str_extract(Review_Text, "(?i)\\b[^.]*Staff[^.]*\\b"))
staff
```

```{r}
plot_staff <- ggplot(staff, aes(Rating)) +
         geom_bar(stat="count", position = "dodge") +
  ggtitle('Rating Distribution for Reviews Mentioned Staff')

plot_ratingall <- ggplot(disneyland, aes(Rating)) +
         geom_bar(stat="count", position = "dodge") +
  ggtitle('Rating Distribution for All Reviews')

plot_staff
plot_ratingall

table(staff$Rating)
table(disneyland$Rating)

staff_prop <- table(staff$Rating)/table(disneyland$Rating)

barplot(staff_prop, main = "The Proportion of Reviews Mentioned Staff", xlab = "Rating in All Reviews", ylab = "Proportion")
```
The plot "Rating Distribution for Reviews Mentioned Staff" shared the same rating distribution pattern as "Rating Distribution for All Reviews". We have the most reviews in rating 5 category, and as the rating decrease the count also decreases.   
We also explored the proportion of reviews mentioned staff over all reviews among all five rating categories. We found that the lower the rating, the larger proportion of reviews mentioned about staff. This might be that visitors having experience with bad customer service or staff with bad attitude would tend to give lower rating.


```{r}
staff %>%
  group_by(Review_ID) %>%
  unnest_tokens(output = word, input = Staff_Sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip() +
  labs(title = "Sentiment Analysis of All Reviews for Staff") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
#observe more positive words than negative words overall

#see if this is true in negative reviews:
staff_Neg <- staff %>%
  filter(Rating_type == "negative")

staff_Neg %>%
  group_by(Review_ID) %>%
  unnest_tokens(output = word, input = Staff_Sentence)%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=sentiment,y=n,fill=sentiment))+
  geom_col()+
  theme_economist()+
  guides(fill=F)+
  coord_flip() +
  labs(title = "Sentiment Analysis of Negative Reviews for Staff") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
#in overall negatively rated reviews, there are more negative review than positive review

#see comparison bewteen review rating and sentiment
library(ggthemes)
staff %>%
  select(Review_ID, Staff_Sentence, Rating)%>%
  group_by(Review_ID, Rating)%>%
  unnest_tokens(output=word,input= Staff_Sentence)%>%
  ungroup()%>%
  inner_join(get_sentiments('bing'))%>%
  group_by(Rating,sentiment)%>%
  summarize(n = n())%>%
  mutate(proportion = n/sum(n))%>%
  ggplot(aes(x= Rating,y=proportion,fill=sentiment))+
  geom_col()+
  theme_economist()+
  coord_flip() + 
  labs(title = "Sentiment Analysis of All Reviews for Staff Across All Rating Categories") +
  theme(plot.title = element_text(size = 10, color = "darkblue"))
```
From the above graphs, we again observe more positive sentiment reviews than negative sentiment reviews in the reviews mentioned about staff. However, in the negatively rated review (with score 1 or 2), the number of negative sentiment exceeds positive sentiments. This could explain that negative description about staff might associate with lower rating.   
For all rating categories, there are both positive and negative sentiment used. Higher rating has higher proportion of positive sentiments.  

```{r}
staff %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Staff_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  arrange(desc(n))

staff %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Staff_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj() +
  labs(title = "NRC Analysis of ALL Reviews Mentioned Staff") +
  theme(plot.title = element_text(size = 10, color = "darkgreen"))

staff_Neg %>%
  group_by(Review_ID)%>%
  unnest_tokens(output = word, input = Staff_Sentence)%>%
  inner_join(nrc)%>%
  group_by(sentiment)%>%
  count()%>%
  ggplot(aes(x=reorder(sentiment,X = n), y=n, fill=sentiment))+
  geom_col()+
  guides(fill=F)+
  coord_flip()+
  theme_wsj() +
  labs(title = "NRC Analysis of ALL Reviews Mentioned Staff") +
  theme(plot.title = element_text(size = 10, color = "darkgreen"))
```
From "NRC Analysis of ALL Reviews Mentioned Staff" graph, the top four emotions are all positive. But in the "NRC Analysis of ALL Reviews Mentioned Staff", the "negative" moved to rank 2. This again proves that in lower rating reviews, there are more negative reviews mentioned about staff. 

### Predictive Models (using TF features)
```{r}
# Add review_rating back to dataframe of features
disneyland_data = cbind(rating = disneyland$Rating,xdtm1)
disneyland_data_tfidf = cbind(rating = disneyland$Rating,xdtm_tfidf1)
head(disneyland_data)
head(disneyland_data_tfidf)
```


We split the new document-term-matrix dataframe using the Term Frequency weighting after adding the rating back into training and testing datasets, where training dataset contains 70% of the dataframe and testing has the rest.

```{r}
set.seed(617)
split = sample(1:nrow(disneyland_data),size = 0.7*nrow(disneyland_data))
train = disneyland_data[split,]
test = disneyland_data[-split,]
```

#### Cart (TF features)

Firstly, we used a regression tree to predict rating using all other variables, term frequencies.
```{r}
library(rpart); library(rpart.plot)
tree = rpart(rating~.,train)
rpart.plot(tree)
```

We applied the predictions of the tree to the test sample to compute root mean square error (RMSE). The RMSE is 0.9900591.
```{r}
pred_tree = predict(tree,newdata=test)
rmse_tree = sqrt(mean((pred_tree - test$rating)^2)); rmse_tree
```


#### Linear Regression (TF features)

Next, we used a regression to predict rating using all other variables, term frequencies. 

```{r}
reg = lm(rating~.,train)
summary(reg)
```

We applied the predictions of linear regression to the test sample. The RMSE is 0.8705454.
```{r}
pred_reg = predict(reg, newdata=test)
rmse_reg = sqrt(mean((pred_reg-test$rating)^2)); rmse_reg
```


Next, we repeated the steps above for the dataset with TF-IDF weight to predict rating.

```{r}
set.seed(617)
split = sample(1:nrow(disneyland_data_tfidf),size = 0.7*nrow(disneyland_data_tfidf))
train = disneyland_data_tfidf[split,]
test = disneyland_data_tfidf[-split,]
```


#### Cart (TF-IDF features)
```{r}
library(rpart); library(rpart.plot)
tree1 = rpart(rating~.,train)
rpart.plot(tree1)
```

We applied the predictions of the tree to the test sample. The RMSE is 0.9900591.
```{r}
pred_tree1 = predict(tree1,newdata=test)
rmse_tree1 = sqrt(mean((pred_tree1 - test$rating)^2)); rmse_tree1
```

#### Linear Regression (TF-IDF features)
```{r, results="hide"}
# the output is the same as the above linear regression, so the output is not included.
reg1 = lm(rating~.,train)
summary(reg1)
```

We applied the predictions of linear regression to the test sample. The RMSE is 0.8705454.
```{r}
pred_reg1 = predict(reg1, newdata=test)
rmse_reg1 = sqrt(mean((pred_reg1 - test$rating)^2)); rmse_reg1
```

Two tree models have the same RMSE for test sample, and so do linear regression models. linear regression models have relative lower RMSE than the tree models. Furthermore, two tree models have almost the same coefficients, and so do linear regressions. In the tree models, money, disappoint, and hours are highlighted to predict the rating, and words related to time, such as "time" and "minute" are significant coefficients in linear regression models (these variables have p-value < 2e-16), which also reveals that waiting time is highly valued by the visitors. The time words plot and the decision trees all illustrate that about an-hour waiting time will lead to a lower rating.Food is also selected as a relative significant variable in the linear regression models, having p-values less than 0.05 in two models. This indicates that food-related issues should be valued by Disneyland Theme Park.







## Conclusion
  In conclusion, the analysis of key factors that visitors care about during their visits and that they give ratings accordingly to different Disneyland branches provides valuable insights to help identify visitors' preferences, expectations, and behaviors. As Disneyland continues to expand its global presence, it must consider these factors to ensure that each location provides unique and authentic experiences to meet visitors' expectations, leading to increased visitor satisfaction and loyalty, contributing to the overall success of Disneyland's global brand. Ultimately, this analysis emphasizes the importance of prioritizing visitor needs and preferences and provides targeted recommendations to support Disneyland to achieve long-term success and maintain its status as a premier entertainment destination.

### RQ1
First, we filtered out some common words that are unnecessary in our study by examining the top 25 words mentioned in the review text. Then, we explored the frequency of top words mentioned by different reviewers coming from different continents. We found that reviewers from different continents mention some same words such as "rides", "time", and "kids", indicating all reviewers care about these topics; and some words appear to be mentioned in different frequencies by reviewers from different continents, for example, "food" is among the top 10 mentioned words in Africa, Asia, Europe, and Oceania reviewers' reviews.
For both the car adventure topic and the food related topic, we first conducted frequency analysis and sentiment analysis using afinn sentiment for the targeted reviewer groups, respectively. We found that the frequency of America and Canada reviewers mentioning car adventure topics was slightly higher than the areas other than America and Canada. This might suggest that America and Canada reviewers tend to mention more about car adventure topics than reviewers from other areas. Moreover, a positive average sentiment score for America and Canada reviews also suggest that these reviewers tend to be happy about their car adventure experiences. 
The frequency of Asian reviewers mentioning food-related topics was lower than areas other than Asia. This suggests that reviewers from Asian countries do not mention food more frequently than reviewers from non-Asian countries. This implies that Asian visitors may care less about food than visitors from non-Asian countries do when they visit the Disney theme parks. However, a positive average sentiment score for Asian reviews suggests that even Asian reviewers may not care about food as much as other reviewers do, they are overall satisfied about the food in the Disney theme parks they visited. 

### RQ2
In the Hong Kong branch, 22.23% of the reviews mentioned shopping topics. In California, only 12.81% mentioned shopping topics, which is much lower than Hong Kong. Surprisingly, 28.27% of the total reviews in the Paris branch have mentioned shopping related topics, which is higher than the Hong Kong branch. We are then able to reject our hypothesis that the Hong Kong branch received similar proportions of shopping related reviews. Moving on to the afinn sentiment analysis. We observed that among all 3 branches, more positive words are in reviews unrelated to shopping experience, and reviews unrelated to shopping experience tend to have more positive tone than reviews that talked about shopping. 

Similar proportions of reviews mentioned ride experiences for California and Paris branches. Hong Kong branch has the least proportions of reviews mentioned ride experiences. In Hong Kong, the average rating is higher for those that mentioned the ride than those that did not mention. However, although the California branch tends to receive the highest ranking among all three branches, the average rating is higher for those that did not mention rides than those that mentioned. Paris tends to receive much lower average ratings compared with the other two, even regardless of mentioning rides or not. This might suggest that visitors are as satisfied about the Paris branch in general as other branches, and the ride experiences might have related to such low ratings. As for the sentiment analysis for this hypothesis, we noticed that the difference in proportion of positive words between reviews with ride experience or not is ambiguous, but the average sentiment score for ride-related reviews are much lower, indicating that reviewers may have more extreme emotions toward ride experience.


### RQ3
We classified topic words into four categories: time, theme rides, dining, and customer services, and we want to see reviews mentioning these topics would affect overall rating. By our analysis, we can conclude the following. For reviews mentioning food, we reject the null hypothesis. In low rating reviews, we observed many reviews discussing food quality. For time words, we reject the null hypothesis. Specifically, when a review mentions a one-hour wait time, the overall rating tends to be lower. For most of the ride's features, we fail to reject the null hypothesis. Meaning that in reviews mentioning specific rides, the features associated with the ride would not affect the review’s overall rating. However, we do find a special case in rides’ drop. Lastly, for reviews mentioning staff, we reject the null hypothesis. We found that in lower rating categories, the  proportion of reviews mentioned about staff is larger than in higher rating categories.

### Recommendation 
Based on results found by previous research questions, recommendations for Disneyland to improve and develop can be divided into two aspects: opening new branches to attract more visitors and improving existing branches to increase overall satisfaction/experience.    
   
##### For Opening new parks:   
1.  Consider the interests and preferences of visitors from different continents when designing the park experience. Visitors from different continents may have different priorities and preferences, as reflected in the differences in the frequency of certain topics mentioned in their reviews. For example, visitors from America and Canada tend to mention car adventure topics more frequently, while visitors from Asia may not care as much about food as visitors from non-Asian countries.  Based on the analysis that visitors from America and Canada tend to mention car adventure topics more frequently, it may be recommended to design or add more car adventure-themed rides in new branches in the Americas. As for Asia, while visitors from this region may not mention food as frequently, it is still important to provide a variety of food options that cater to different tastes and preferences. It may also be beneficial to design or add more cultural-themed rides or attractions that showcase the unique heritage and traditions of the region. Overall, it is important to consider the interests and preferences of visitors from different continents when designing the park experience to provide a more satisfying and enjoyable experience for all visitors.   
2.  Improving branches’ support facilities to cater visitors from different countries and continents needs. For example, in the Paris branch, 28.27% of reviews mentioned shopping-related topics, which is higher than Hong Kong and California branches. By adding more Disney co-branded stores in France, Disney could collaborate with French fashion brands or designers to create exclusive products that combine French fashion with Disney's popular characters and stories. This could appeal to French visitors who are interested in fashion and design and add a unique touch to the merchandise offerings.    

##### Exisiting Parks: 
As for improving existing parks, recommendations are provided based on four sections: food, time, ride, and staff.     
*Food: *       
1. Disneyland should address the issues of overpricing, limited and unclean dining options, poor quality/unhealthy food, and long waiting times. These problems have been highlighted in many negative reviews and are supported by the predictive model's analysis. To improve, Disneyland can consider building more restaurants and offering online ordering to reduce waiting times.
2. Disneyland could consider expanding and diversifying its food options, particularly in non-Asian parks where food is mentioned more frequently. They could also focus on improving the quality and taste of their current food options to increase overall visitor satisfaction.    
*Time: *   
1. Visitors have expressed dissatisfaction with waiting times of more than an hour, which has led to lower ratings. Disneyland can try to reduce waiting times by improving queue management, offering fast pass or similar systems, or increasing the number of staff during peak periods.   
*Ride:*  
1. Most ride-related factors were found to have no significant impact on overall ratings, except for the number of drops. High-rated reviews mentioned more non-drop attractions. Therefore, Disneyland could consider adding non-drop attractions to improve overall visitor satisfaction.    
2. Disneyland could focus on expanding and diversifying its ride offerings to attract a wider range of visitors based on different visitors’ preferences based on different countries. They could also prioritize the maintenance and upkeep of their current rides to ensure a high-quality experience for visitors.  
*Staff:*    
1. Visitors have complained about employees not doing their job, having a poor attitude, and not speaking English in the case of Hong Kong Disneyland. Disneyland should address these issues by providing employee training in language skills, customer service, and direction to improve the overall visitor experience.

### Limitation 
First, in our dataset, there is only “review_id” which is unique for each review, the “reviewer_id” represents each unique user is not included and remains unknown, we were not able to examine the reviews that one person wrote for different Disneyland park locations, and we were also unable to rule out the possibility of one reviewer leaving multiple reviews for one Disneyland park location.
Second, Our analysis only focuses on the reviews towards Disneyland parks located in Paris, Hong Kong, and California; there are Disneyland parks in other cities and countries that are not included in the analysis and the review data was not included and analyzed in our study, therefore the generalizability of our study may be limited.
Third, there might exist errors in the process of matching the ride names with the review texts, it is possible that some of the Disney character names were falsely matched with a ride name; additionally, our study was not able to identify the reviews with spelling errors and match them with the correct ride names. Therefore, our analysis may contain a small portion of inaccurate data and may miss some accurate data.
Finally, our study did not rule out the impact of visiting time, seasonality, and year on reviews and ratings, since Disneyland parks have peak and off seasons, the time of visit exists as a confounding variable in our study. In addition to it, the overall text analysis could not tell some other sentiments like irony ones, the sentiment analysis is limited by the lack of variety of sentiments.

### Future Study 
Based on the sentiment analysis conducted on the Disneyland review dataset, several suggestions for future studies can be made.
First of all, future studies could consider selecting more topics to investigate the impact that may have on visitor ratings. For instance, topics such as kids and children experiences could reveal insights on how Disneyland parks create childhood memories and shape family relationships. Similarly, the interaction between travelers and animation characters could also expose the immersive experiences. Fireworks are another core component in Disneyland experiences, further analysis on fireworks could also focus on this element and explore Disneyland’s nighttime experience.
Secondly, the tree models used in this study identified the factor "money" as a significant variable, hence, future studies could further investigate the financial factors which would largely impact visitors’ perception of the park. Such an investigation could focus on the costs of tickets, food, merchandise and other expenses outside of the park like nearby hotels and transportation costs. It could also examine how visitors feel about the pricing of these factors and if they feel the expenses are worth it.
Thirdly, this study did not take into account the issue of time. Follow-up scholars could divide the time into off-season and peak season for research, like comparing the visitor ratings between these two time ranges to explore the impact of crowds and wait time on visitor experience, and this would make the research more comprehensive.
Finally, it's important to note that the data only comes from three branches of Disneyland. Including data from other branches or Disney parks worldwide could provide a more diverse and comprehensive understanding of the factors that impact visitor ratings. Additionally, it could help identify more regional differences in visitor perceptions of Disney parks and provide valuable insights into how the park can better cater to the needs and preferences of visitors from different parts of the world.





## References
Luo, J., Li, G., Li, G., & Law, R. (2020). Topic modelling for theme park online reviews: analysis of Disneyland. *Journal of Travel & Tourism Marketing*, 37(2), 272–285. https://doi.org/10.1080/10548408.2020.1740138   

*Disneyland Reviews*. (2021, January 19). Kaggle. https://www.kaggle.com/datasets/arushchillar/disneyland-reviews  

*Walt Disney World Ride Data - dataset by lynne588*. (2023, March 15). Data.world. https://data.world/lynne588/walt-disney-world-ride-data

